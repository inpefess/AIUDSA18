{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction number of stars for a review\n",
    "\n",
    "Our dataset is quite large, about 6GB. For debugging our code, we will use [sample](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=sample#pyspark.sql.DataFrame.sample) after reading the JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_on_hdfs = \"/user/borisshminke/data/yelp_academic_dataset_review.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|_iEl9sCLsvXEFHUWP...|   1|2017-08-16 17:57:23|    0|wI9BR4DNU99C_dvY-...|  4.0|Really 3.5\n",
      "\n",
      "I thi...|     0|f77_FtAlN-8H4bUdu...|\n",
      "|MUad5l6z0Z3fwdpb4...|   0|2015-09-27 20:45:18|    1|zrIFeuDJhZZ7Ce-K5...|  2.0|Cool concept - an...|     1|yXVhmdBFBmU3DIu9Y...|\n",
      "|yHejLbG91ThJIn2xp...|   0|2019-01-23 14:38:13|    0|b2DO8cH6ooKQKcCxC...|  5.0|I eat at this pla...|     0|NZYeGIBbwDKYTwYou...|\n",
      "|P0-zxLhfe9iOgidDG...|   0|2019-05-15 04:51:51|    0|Ryc_Aep4hkl6YBv0Y...|  5.0|This place is wit...|     1|daow2AoiYJGMrbrcl...|\n",
      "|3kdSl5mo9dWC4clrQ...|   0|2018-12-28 03:58:43|    0|smvKWyooBL-5UFNfd...|  5.0|Great place to go...|     0|dtgl2P30tNcF3_1HQ...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.json(reviews_on_hdfs).sample(0.000001)\n",
    "reviews.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data\n",
    "\n",
    "Spark has a vast library of feature engineering functions. For example, we can get TF-IDF representation for our review corpus. In the following snippet we construct a data preparation pipeline with three stages:\n",
    "1. we get review text parsed into words\n",
    "1. we count term frequencies of our bags of words\n",
    "1. we normalise by inverted document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|      term_frequency|           embedding|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Really 3.5\n",
      "\n",
      "I thi...|[really, 3.5, , i...|(262144,[14,1998,...|(262144,[14,1998,...|\n",
      "|Cool concept - an...|[cool, concept, -...|(262144,[15889,16...|(262144,[15889,16...|\n",
      "|I eat at this pla...|[i, eat, at, this...|(262144,[12888,15...|(262144,[12888,15...|\n",
      "|This place is wit...|[this, place, is,...|(262144,[9639,136...|(262144,[9639,136...|\n",
      "|Great place to go...|[great, place, to...|(262144,[1889,231...|(262144,[1889,231...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 105 ms, sys: 20.6 ms, total: 125 ms\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "\n",
    "data_preparation = Pipeline(stages=[\n",
    "    Tokenizer(inputCol=\"text\", outputCol=\"words\"),\n",
    "    HashingTF(inputCol=\"words\", outputCol=\"term_frequency\"),\n",
    "    IDF(inputCol=\"term_frequency\", outputCol=\"embedding\")\n",
    "])\n",
    "prepared_reviews = data_preparation.fit(reviews).transform(reviews)\n",
    "prepared_reviews.select(\"text\", \"words\", \"term_frequency\", \"embedding\").show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into the details of the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text=u\"Really 3.5\\n\\nI think came here in an off night.\\nFirst I wanted the beautiful tacos I see in the photos  on Yelp.  The menu I had only had one taco on it.  When I asked the waiter.  He told me that was the only menu they had.  I then ordered the fried burrito and it looked amazing!!! \\n\\n\\nHowever the burrito tasted pretty bad.\\n\\nI don't think I'll be coming back here.\", words=[u'really', u'3.5', u'', u'i', u'think', u'came', u'here', u'in', u'an', u'off', u'night.', u'first', u'i', u'wanted', u'the', u'beautiful', u'tacos', u'i', u'see', u'in', u'the', u'photos', u'', u'on', u'yelp.', u'', u'the', u'menu', u'i', u'had', u'only', u'had', u'one', u'taco', u'on', u'it.', u'', u'when', u'i', u'asked', u'the', u'waiter.', u'', u'he', u'told', u'me', u'that', u'was', u'the', u'only', u'menu', u'they', u'had.', u'', u'i', u'then', u'ordered', u'the', u'fried', u'burrito', u'and', u'it', u'looked', u'amazing!!!', u'', u'', u'', u'however', u'the', u'burrito', u'tasted', u'pretty', u'bad.', u'', u'i', u\"don't\", u'think', u\"i'll\", u'be', u'coming', u'back', u'here.'], term_frequency=SparseVector(262144, {14: 1.0, 1998: 1.0, 24417: 7.0, 24980: 1.0, 25570: 1.0, 30465: 1.0, 35584: 1.0, 48448: 1.0, 49470: 1.0, 50424: 2.0, 51531: 1.0, 52914: 1.0, 58211: 1.0, 65844: 1.0, 70028: 2.0, 73366: 1.0, 81307: 1.0, 82111: 1.0, 86175: 1.0, 91677: 1.0, 100258: 2.0, 103838: 7.0, 113418: 1.0, 119409: 1.0, 121195: 1.0, 125133: 2.0, 125372: 1.0, 132270: 1.0, 146511: 1.0, 148039: 1.0, 149534: 1.0, 150319: 1.0, 151536: 1.0, 151571: 2.0, 165345: 1.0, 167152: 1.0, 171871: 1.0, 175449: 1.0, 181635: 2.0, 188822: 1.0, 190355: 1.0, 193889: 1.0, 194536: 1.0, 206116: 1.0, 215995: 1.0, 221047: 1.0, 222453: 2.0, 229704: 1.0, 233585: 1.0, 242101: 1.0, 249180: 10.0, 252917: 1.0, 258125: 1.0, 258795: 1.0}), embedding=SparseVector(262144, {14: 1.6094, 1998: 1.6094, 24417: 2.4967, 24980: 1.204, 25570: 0.6931, 30465: 1.6094, 35584: 1.204, 48448: 0.9163, 49470: 1.6094, 50424: 3.2189, 51531: 1.6094, 52914: 1.204, 58211: 1.6094, 65844: 0.9163, 70028: 3.2189, 73366: 1.204, 81307: 1.6094, 82111: 1.204, 86175: 0.5108, 91677: 0.0, 100258: 2.4079, 103838: 0.0, 113418: 1.204, 119409: 1.6094, 121195: 1.6094, 125133: 2.4079, 125372: 0.9163, 132270: 1.204, 146511: 1.6094, 148039: 1.6094, 149534: 1.204, 150319: 1.204, 151536: 1.204, 151571: 3.2189, 165345: 1.6094, 167152: 1.204, 171871: 1.6094, 175449: 1.6094, 181635: 3.2189, 188822: 1.204, 190355: 1.6094, 193889: 1.6094, 194536: 0.9163, 206116: 1.6094, 215995: 1.6094, 221047: 1.6094, 222453: 1.0217, 229704: 1.6094, 233585: 1.6094, 242101: 1.6094, 249180: 5.1083, 252917: 1.204, 258125: 1.6094, 258795: 1.204}))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_reviews.select(\"text\", \"words\", \"term_frequency\", \"embedding\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind the representation of TF-IDF vectors - it's sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do It Yourself\n",
    "\n",
    "Try to follow [a tutorial from Spark docs](http://spark.apache.org/docs/latest/ml-classification-regression.html#regression)\n",
    "\n",
    "* calculate `word2vec` embeddings instead of TF-IDF\n",
    "* build a linear regression (predict stars by text)\n",
    "* split data into train and validation sets and evaluate your model\n",
    "* compare quality of models (TF-IDF vs word2vec, linear vs random forest vs gradient goosted trees)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
