{"cells":[{"cell_type":"markdown","source":["# Prediction of the number of fans by an album title\n\nBefore working with the full dataset, consider debuggin the pipeline on a [sample](https://spark.apache.org/docs/3.2.1/api/python/reference/pyspark.pandas/api/pyspark.pandas.DataFrame.sample.html)."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da2eec1e-0129-4b55-8a3c-d9947fd79e2e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark import pandas as pd\n\npd.set_option(\"compute.default_index_type\", \"distributed\")\ndata = pd.read_json(\"dbfs:///data.json_lines\").sample(frac=1.0)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0170c03d-ed70-442c-9e26-9513f05ff28c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# since we want to predict the number of fans\n# we drop the lines where fan column is empty\ndata = data[~data.deezerFans.isnull()]\ndata[[\"title\", \"deezerFans\"]].head()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4d600e2d-4151-4663-9def-2c0d678c8d37","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>deezerFans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Despierta</td>\n      <td>2046</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Det Var En Gång En Fågel</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Nein, Mann!</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Some Things</td>\n      <td>1688</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Far Away</td>\n      <td>1157</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>deezerFans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Despierta</td>\n      <td>2046</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Det Var En Gång En Fågel</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Nein, Mann!</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Some Things</td>\n      <td>1688</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Far Away</td>\n      <td>1157</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Transforming Data\n\nSpark has a vast library of feature engineering functions. For example, we can get TF-IDF representation for album titles. In the following snippet we construct a data preparation pipeline with three stages:\n1. we get title parsed into words\n1. we count term frequencies of our bags of words\n1. we normalise by inverted document frequency"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"59913cc3-87ec-4dc8-a6e3-cd48fe0279d7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.pipeline import Pipeline\nfrom pyspark.ml.feature import Tokenizer, HashingTF, IDF\n\ndata_preparation = Pipeline(stages=[\n    Tokenizer(inputCol=\"title\", outputCol=\"words\"),\n    HashingTF(inputCol=\"words\", outputCol=\"term_frequency\"),\n    IDF(inputCol=\"term_frequency\", outputCol=\"embedding\")\n])\nspark_data = data.spark.frame()\nprepared_data = data_preparation.fit(spark_data).transform(spark_data)"],"metadata":{"scrolled":true,"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ee0f56c2-9f88-4804-b108-2ccc0247bfea","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's look into the details of the first row:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8100c67f-1b04-44eb-a2d1-88b2471c33c5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["prepared_data[[\"title\", \"words\", \"term_frequency\", \"embedding\"]].head(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eb9720f8-7e92-4236-bff7-db6b3a0515b2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[4]: [Row(title='Despierta', words=['despierta'], term_frequency=SparseVector(262144, {13861: 1.0}), embedding=SparseVector(262144, {13861: 10.8552})),\n Row(title='Det Var En Gång En Fågel', words=['det', 'var', 'en', 'gång', 'en', 'fågel'], term_frequency=SparseVector(262144, {32297: 2.0, 62868: 1.0, 84301: 1.0, 133624: 1.0, 228947: 1.0}), embedding=SparseVector(262144, {32297: 11.2447, 62868: 8.062, 84301: 11.2607, 133624: 11.2607, 228947: 9.0094})),\n Row(title='Nein, Mann!', words=['nein,', 'mann!'], term_frequency=SparseVector(262144, {85958: 1.0, 150003: 1.0}), embedding=SparseVector(262144, {85958: 11.2607, 150003: 10.8552})),\n Row(title='Some Things', words=['some', 'things'], term_frequency=SparseVector(262144, {19208: 1.0, 214676: 1.0}), embedding=SparseVector(262144, {19208: 7.0122, 214676: 6.5739})),\n Row(title='Far Away', words=['far', 'away'], term_frequency=SparseVector(262144, {9129: 1.0, 165678: 1.0}), embedding=SparseVector(262144, {9129: 6.8976, 165678: 7.3487}))]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[4]: [Row(title='Despierta', words=['despierta'], term_frequency=SparseVector(262144, {13861: 1.0}), embedding=SparseVector(262144, {13861: 10.8552})),\n Row(title='Det Var En Gång En Fågel', words=['det', 'var', 'en', 'gång', 'en', 'fågel'], term_frequency=SparseVector(262144, {32297: 2.0, 62868: 1.0, 84301: 1.0, 133624: 1.0, 228947: 1.0}), embedding=SparseVector(262144, {32297: 11.2447, 62868: 8.062, 84301: 11.2607, 133624: 11.2607, 228947: 9.0094})),\n Row(title='Nein, Mann!', words=['nein,', 'mann!'], term_frequency=SparseVector(262144, {85958: 1.0, 150003: 1.0}), embedding=SparseVector(262144, {85958: 11.2607, 150003: 10.8552})),\n Row(title='Some Things', words=['some', 'things'], term_frequency=SparseVector(262144, {19208: 1.0, 214676: 1.0}), embedding=SparseVector(262144, {19208: 7.0122, 214676: 6.5739})),\n Row(title='Far Away', words=['far', 'away'], term_frequency=SparseVector(262144, {9129: 1.0, 165678: 1.0}), embedding=SparseVector(262144, {9129: 6.8976, 165678: 7.3487}))]"]}}],"execution_count":0},{"cell_type":"markdown","source":["Mind the representation of TF-IDF vectors - it's sparse."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85d1d271-6f28-40d7-a4b5-7e3cc3fbc442","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# Do It Yourself\n\nTry to follow [a tutorial from Spark docs](https://spark.apache.org/docs/3.2.1/ml-classification-regression.html#regression)\n\n* calculate `word2vec` embeddings instead of TF-IDF\n* build a linear regression (predict the number of fans by title)\n* split data into train and validation sets and evaluate your model\n* compare quality of models (TF-IDF vs word2vec, linear vs random forest vs gradient goosted trees)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6778598d-653e-46b5-bd70-3acf2e84038e","inputWidgets":{},"title":""}}}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.14","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"spark-ml","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":221813743776142}},"nbformat":4,"nbformat_minor":0}
