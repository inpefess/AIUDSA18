{"cells":[{"cell_type":"markdown","source":["# Pandas API\n\nStarting from version 3.2.0, Spark supports [Pandas API](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_ps.html). When using it, one can work with Spark DataFrames as if they were Pandas ones. Remember though, they never really are!"],"metadata":{"tags":[],"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b85040f7-aa1e-400d-9033-3183c9d24f69","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark import pandas as pd\n\npd.set_option(\"compute.default_index_type\", \"distributed\")\ndata = pd.read_json(\"dbfs:///data.json_lines\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f49861d8-9d58-475e-b29f-f8f8f426fa24","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["len(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"889614e5-47d5-48af-a264-60ca6209ea68","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[2]: 208743","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[2]: 208743"]}}],"execution_count":0},{"cell_type":"markdown","source":["# SQL API"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b2c505c-9717-481a-8906-2f80309760c7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# we can easily regiter a DataFrame as a table\ndata.spark.frame().createOrReplaceTempView(\"data\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a8ff197-5b10-4647-a85f-73c13a52b384","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# now we can write SQL queries as to any database\n# notice that before we ask Spark to ``show``\n# everything is a 'transformation', not an 'action'\n# so it's like creating views\nspark.sql(\"\"\"\nSELECT\n    COUNT(*) AS cnt\nFROM data\n\"\"\").createOrReplaceTempView(\"count\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1d8008e6-b986-49bc-8deb-46b0dd083dac","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# here the action happens and we see the result set\nspark.sql(\"SELECT * FROM count LIMIT 1\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dc69f00e-aa6c-4430-b5f3-c113a3bafc18","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+\n|   cnt|\n+------+\n|208743|\n+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+\n|   cnt|\n+------+\n|208743|\n+------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Spark DataFrames"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8559f3ed-eb08-4aa3-864d-992e24be63b7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# this API is rather different from both SQL and Pandas\n# but provides most of the functionality\nfrom pyspark.sql.functions import count_distinct\ndata_df = data.spark.frame()\ndata_df.select(\n    count_distinct(\"genre\").alias(\"number_of_ranks\")\n).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6a960d29-c1a9-40ea-8d22-be13c2254c76","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------------+\n|number_of_ranks|\n+---------------+\n|            528|\n+---------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------------+\n|number_of_ranks|\n+---------------+\n|            528|\n+---------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Do It Yourself\n\n[Spark Manual](https://spark.apache.org/docs/latest/api/python/reference) is your best friend!\n\n* count numbers of albums, artists, countries, languages, genres\n* find ten longest and sortest albumns\n* find top ten countries where the maximal number of albums is available\n* build a table of total duration of all albums appeared yearly for every country\n* find an artist working in the largest number of different genres\n* find ten most frequent words from a title in ten most popular languages\n\nWhen done with your favourite API, try doing the same with another one!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7a9620c2-f4df-472b-9986-c949ea979dab","inputWidgets":{},"title":""}}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.10","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"data-munging","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":221813743776125}},"nbformat":4,"nbformat_minor":0}
