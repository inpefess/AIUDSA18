{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session\n",
    "\n",
    "Spark can work with data located on HDFS or a non-distributed filesystem. It can also use YARN from Hadoop, or [Mesos](https://mesos.apache.org/), or a resource manager of its own. For this example we use the last option.\n",
    "\n",
    "All distributed operations with Spark are done using so-called Spark Session. Let's create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://math11.unice.fr:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f80efd3ce48>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"100g\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we limit an amount of memory used to prevent Spark trying to eat all the server. Configuring Spark might be tricky at times. When you work on a dedicated Spark cluster, your admin will probably create a session for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data\n",
    "\n",
    "Spark can consume data in a variety of formats, e.g. in JSON. We use the [YELP Dataset](https://www.yelp.com/dataset) for this example. It's easily obtainable and free to use in education and research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 ms, sys: 1.85 ms, total: 3.84 ms\n",
      "Wall time: 601 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark.read.text(\"/home/boris/Downloads/yelp_dataset/yelp_academic_dataset_review.json\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code simply reads a JSON file as a text, line by line, and counts the number of lines. Let's compare the speed with `wc` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8021122 /home/boris/Downloads/yelp_dataset/yelp_academic_dataset_review.json\n",
      "wc -l /home/boris/Downloads/yelp_dataset/yelp_academic_dataset_review.json  0,44s user 1,27s system 99% cpu 1,706 total\n"
     ]
    }
   ],
   "source": [
    "!time wc -l /home/boris/Downloads/yelp_dataset/yelp_academic_dataset_review.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although `wc` is implemented in C and is more efficient in general than JVM code behind Spark, it uses only one CPU, thus working several times slower than it's distributed counterpart from Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing JSON in Spark is really simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|PmYIuaV18eyr5IMXZ...|   0|2015-03-04 20:37:18|    0|H1hdeQ1TdZ4fF1Gct...|  3.0|I've got a 2 hour...|     0|gj7dwFiadFO5gyrH8...|\n",
      "|5gl2GLgimBz1-Q-uX...|   1|2016-01-30 03:26:26|    2|mscF94aHl77US0MB1...|  5.0|Excellent pizza! ...|     2|yzF_-JtpMVPqM-TnY...|\n",
      "|Zw9wEAk9L6oTZi63f...|   0|2017-03-27 03:17:02|    0|tN-8bLuiQc4wZ9G-z...|  4.0|Food is yummy, ho...|     0|rIvh-c-Qkhme6FG0d...|\n",
      "|0TBTV3q6QXCn9vNhy...|   0|2017-03-15 05:15:48|    0|9WsORk6y22cnCqRdC...|  5.0|My wife is gluten...|     0|Bn0xnhjUMOQib_Y-7...|\n",
      "|MDtMV0ld7q0BsQPKN...|   0|2014-02-05 18:37:14|    0|XJvECqxFNuAB5nhTG...|  5.0|The best chain bu...|     0|TMvcS_zpVt_o9gt3G...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.json(\n",
    "    \"/home/boris/Downloads/yelp_dataset/yelp_academic_dataset_review.json\"\n",
    ").sample(0.01)\n",
    "reviews.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use only 1% of all data, since it's about 6GB. If you have a sufficiently large cluster of you're ready to way more than several minutes, you can change the sampling ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data\n",
    "\n",
    "Spark has a vast library of feature engineering functions. For example, we can get TF-IDF representation for our review corpus. In the following snippet we construct a data preparation pipeline with three stages:\n",
    "1. we get review text parsed into words\n",
    "1. we count term frequencies of our bags of words\n",
    "1. we normalise by inverted document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|               words|           embedding|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|I've got a 2 hour...|[i've, got, a, 2,...|[-0.0149417100758...|\n",
      "|Excellent pizza! ...|[excellent, pizza...|[0.01702762021929...|\n",
      "|Food is yummy, ho...|[food, is, yummy,...|[-0.0035166407428...|\n",
      "|My wife is gluten...|[my, wife, is, gl...|[0.05412049598267...|\n",
      "|The best chain bu...|[the, best, chain...|[0.00780793732867...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 146 ms, sys: 30.7 ms, total: 177 ms\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|      term_frequency|           embedding|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|I've got a 2 hour...|[i've, got, a, 2,...|(262144,[7221,844...|(262144,[7221,844...|\n",
      "|Excellent pizza! ...|[excellent, pizza...|(262144,[1689,870...|(262144,[1689,870...|\n",
      "|Food is yummy, ho...|[food, is, yummy,...|(262144,[12409,27...|(262144,[12409,27...|\n",
      "|My wife is gluten...|[my, wife, is, gl...|(262144,[4959,553...|(262144,[4959,553...|\n",
      "|The best chain bu...|[the, best, chain...|(262144,[1689,182...|(262144,[1689,182...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 22.9 ms, sys: 8.32 ms, total: 31.2 ms\n",
      "Wall time: 4.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "\n",
    "data_preparation = Pipeline(stages=[\n",
    "    Tokenizer(inputCol=\"text\", outputCol=\"words\"),\n",
    "    HashingTF(inputCol=\"words\", outputCol=\"term_frequency\"),\n",
    "    IDF(inputCol=\"term_frequency\", outputCol=\"embedding\")\n",
    "])\n",
    "prepared_reviews = data_preparation.fit(reviews).transform(reviews)\n",
    "prepared_reviews.select(\"text\", \"words\", \"term_frequency\", \"embedding\").show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into the details of the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text=\"I've got a 2 hour layover so armed with my trusty ipad I decided to review this box restaurant. I usually don't review places like this. They are all the same to me.  Food is on the average side. I ordered a chilli, coffee, and a donut.  The food tastes the same as every other T Hortons I've been to. That's the advantage of these box restaurants, generally there are no surprises. \\n\\nMy tirade is going to be on the service staff. These women are awful!  The counter person who served me did not dare look me in the eyes when addressing me. Avoiding eye contact, looking down, she mumbled something incoherent to me. I had to ask her twice what she was trying to say to me. She wanted to know what kind of bun do I want with my chilli.... Whole wheat or white.\\n\\nI know many of the counter people who work at T Hortons are immigrants working for min wage and they are working long hours, but have a bit of empathy!  A weary traveler would certainly appreciate a friendly smile and a sweet disposition!  I think showing that you're happy can make you feel happy!  Just food for thought....  Something to think about on your next coffee break.\", words=[\"i've\", 'got', 'a', '2', 'hour', 'layover', 'so', 'armed', 'with', 'my', 'trusty', 'ipad', 'i', 'decided', 'to', 'review', 'this', 'box', 'restaurant.', 'i', 'usually', \"don't\", 'review', 'places', 'like', 'this.', 'they', 'are', 'all', 'the', 'same', 'to', 'me.', '', 'food', 'is', 'on', 'the', 'average', 'side.', 'i', 'ordered', 'a', 'chilli,', 'coffee,', 'and', 'a', 'donut.', '', 'the', 'food', 'tastes', 'the', 'same', 'as', 'every', 'other', 't', 'hortons', \"i've\", 'been', 'to.', \"that's\", 'the', 'advantage', 'of', 'these', 'box', 'restaurants,', 'generally', 'there', 'are', 'no', 'surprises.', '', '', 'my', 'tirade', 'is', 'going', 'to', 'be', 'on', 'the', 'service', 'staff.', 'these', 'women', 'are', 'awful!', '', 'the', 'counter', 'person', 'who', 'served', 'me', 'did', 'not', 'dare', 'look', 'me', 'in', 'the', 'eyes', 'when', 'addressing', 'me.', 'avoiding', 'eye', 'contact,', 'looking', 'down,', 'she', 'mumbled', 'something', 'incoherent', 'to', 'me.', 'i', 'had', 'to', 'ask', 'her', 'twice', 'what', 'she', 'was', 'trying', 'to', 'say', 'to', 'me.', 'she', 'wanted', 'to', 'know', 'what', 'kind', 'of', 'bun', 'do', 'i', 'want', 'with', 'my', 'chilli....', 'whole', 'wheat', 'or', 'white.', '', 'i', 'know', 'many', 'of', 'the', 'counter', 'people', 'who', 'work', 'at', 't', 'hortons', 'are', 'immigrants', 'working', 'for', 'min', 'wage', 'and', 'they', 'are', 'working', 'long', 'hours,', 'but', 'have', 'a', 'bit', 'of', 'empathy!', '', 'a', 'weary', 'traveler', 'would', 'certainly', 'appreciate', 'a', 'friendly', 'smile', 'and', 'a', 'sweet', 'disposition!', '', 'i', 'think', 'showing', 'that', \"you're\", 'happy', 'can', 'make', 'you', 'feel', 'happy!', '', 'just', 'food', 'for', 'thought....', '', 'something', 'to', 'think', 'about', 'on', 'your', 'next', 'coffee', 'break.'], term_frequency=SparseVector(262144, {7221: 1.0, 8449: 1.0, 11104: 2.0, 12524: 1.0, 16168: 1.0, 18700: 1.0, 19036: 7.0, 22370: 2.0, 22575: 2.0, 22860: 1.0, 24303: 1.0, 24980: 1.0, 27576: 9.0, 29977: 2.0, 33123: 1.0, 33917: 1.0, 34343: 1.0, 38911: 1.0, 42404: 1.0, 43756: 1.0, 48448: 1.0, 50001: 2.0, 53814: 1.0, 54961: 1.0, 55039: 1.0, 56163: 1.0, 57058: 2.0, 58267: 5.0, 61899: 1.0, 67416: 3.0, 71450: 2.0, 73445: 1.0, 79132: 1.0, 80651: 2.0, 80707: 1.0, 81566: 2.0, 83104: 1.0, 83888: 1.0, 86617: 1.0, 86676: 1.0, 89717: 1.0, 90723: 1.0, 92273: 1.0, 95017: 1.0, 95889: 9.0, 96611: 1.0, 97171: 1.0, 98221: 1.0, 98431: 1.0, 99211: 1.0, 101176: 1.0, 102382: 1.0, 103497: 4.0, 106776: 2.0, 106841: 2.0, 107107: 7.0, 108437: 1.0, 108541: 1.0, 110689: 1.0, 112811: 1.0, 113398: 1.0, 115994: 1.0, 117491: 1.0, 118021: 1.0, 119453: 1.0, 120043: 1.0, 121133: 3.0, 122768: 1.0, 124884: 1.0, 126466: 2.0, 129508: 1.0, 137765: 1.0, 137855: 1.0, 140931: 2.0, 143741: 2.0, 145207: 1.0, 146303: 1.0, 148101: 1.0, 151536: 2.0, 152049: 1.0, 153423: 2.0, 156125: 1.0, 156550: 1.0, 157726: 1.0, 157865: 1.0, 158511: 1.0, 159212: 1.0, 163000: 1.0, 171222: 1.0, 172164: 2.0, 175997: 1.0, 176257: 1.0, 176497: 1.0, 178875: 1.0, 182451: 1.0, 183411: 1.0, 184046: 1.0, 185559: 1.0, 185880: 1.0, 186312: 1.0, 187114: 1.0, 190143: 1.0, 190256: 1.0, 193453: 1.0, 196670: 1.0, 198117: 1.0, 198589: 1.0, 202009: 2.0, 204870: 1.0, 206312: 1.0, 208258: 1.0, 211980: 3.0, 214962: 1.0, 218098: 1.0, 219087: 4.0, 219646: 1.0, 219766: 1.0, 219915: 3.0, 221576: 1.0, 221693: 1.0, 222250: 1.0, 223763: 1.0, 224040: 1.0, 225898: 1.0, 227001: 1.0, 227431: 1.0, 227983: 1.0, 228250: 1.0, 228685: 1.0, 230912: 1.0, 231213: 1.0, 235273: 1.0, 235406: 2.0, 240944: 3.0, 244489: 1.0, 245044: 1.0, 246599: 1.0, 248192: 1.0, 249180: 10.0, 249711: 1.0, 250855: 1.0, 253475: 1.0, 254352: 1.0, 255015: 1.0, 257485: 1.0, 258203: 1.0, 261499: 1.0}), embedding=SparseVector(262144, {7221: 1.9596, 8449: 5.3772, 11104: 5.9435, 12524: 2.7233, 16168: 6.6587, 18700: 1.7007, 19036: 2.3167, 22370: 9.6237, 22575: 6.0427, 22860: 10.6003, 24303: 4.8965, 24980: 1.511, 27576: 2.6719, 29977: 12.8062, 33123: 3.3489, 33917: 0.8046, 34343: 2.8725, 38911: 5.3799, 42404: 1.397, 43756: 1.52, 48448: 0.8962, 50001: 3.0777, 53814: 5.9321, 54961: 2.5994, 55039: 1.8379, 56163: 4.6976, 57058: 5.6425, 58267: 5.5041, 61899: 2.8721, 67416: 2.6454, 71450: 7.3761, 73445: 4.3246, 79132: 3.2498, 80651: 8.4831, 80707: 3.4055, 81566: 3.4643, 83104: 8.9908, 83888: 7.003, 86617: 5.6167, 86676: 8.4602, 89717: 2.2539, 90723: 3.1453, 92273: 4.1195, 95017: 9.9071, 95889: 0.9803, 96611: 4.1795, 97171: 1.4177, 98221: 4.3551, 98431: 3.23, 99211: 0.5128, 101176: 6.3956, 102382: 2.3055, 103497: 12.4783, 106776: 1.0258, 106841: 1.083, 107107: 1.7986, 108437: 1.857, 108541: 0.6835, 110689: 4.6354, 112811: 7.8277, 113398: 7.1991, 115994: 2.0427, 117491: 1.062, 118021: 10.1948, 119453: 1.6192, 120043: 2.1641, 121133: 3.9356, 122768: 3.2871, 124884: 4.7239, 126466: 1.5303, 129508: 3.1193, 137765: 2.7885, 137855: 1.5497, 140931: 4.8394, 143741: 4.7156, 145207: 1.1354, 146303: 3.7407, 148101: 3.0491, 151536: 1.6906, 152049: 3.5489, 153423: 5.214, 156125: 7.5092, 156550: 3.2998, 157726: 8.7285, 157865: 5.1113, 158511: 8.2489, 159212: 3.5668, 163000: 2.796, 171222: 2.5991, 172164: 7.0046, 175997: 5.2135, 176257: 1.9387, 176497: 2.5736, 178875: 10.6003, 182451: 5.8338, 183411: 2.928, 184046: 3.3995, 185559: 2.3978, 185880: 5.6235, 186312: 1.8301, 187114: 1.1105, 190143: 3.5663, 190256: 2.5159, 193453: 5.2089, 196670: 7.8594, 198117: 5.4298, 198589: 1.3574, 202009: 17.0417, 204870: 6.3376, 206312: 2.8322, 208258: 1.4611, 211980: 6.5814, 214962: 1.0153, 218098: 4.6354, 219087: 2.0417, 219646: 7.1826, 219766: 4.6483, 219915: 0.3452, 221576: 2.6139, 221693: 0.9834, 222250: 8.2024, 223763: 3.0602, 224040: 2.8794, 225898: 1.9266, 227001: 2.1783, 227431: 1.7286, 227983: 6.8161, 228250: 1.4539, 228685: 2.4106, 230912: 2.9604, 231213: 4.8637, 235273: 1.0006, 235406: 4.236, 240944: 2.1254, 244489: 9.9071, 245044: 2.6739, 246599: 8.2977, 248192: 5.8467, 249180: 6.0503, 249711: 6.1875, 250855: 0.5956, 253475: 0.9322, 254352: 5.2603, 255015: 9.9071, 257485: 7.6558, 258203: 9.684, 261499: 7.6558}))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_reviews.select(\"text\", \"words\", \"term_frequency\", \"embedding\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind the representation of TF-IDF vectors - it's sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do It Yourself\n",
    "* calculate `word2vec` embeddings instead of TF-IDF\n",
    "* build a linear regression (predict stars by text)\n",
    "* split data into train and validation sets and evaluate your model\n",
    "* compare quality of models (TF-IDF vs word2vec, linear vs random forest vs gradient goosted trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
