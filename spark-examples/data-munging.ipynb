{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session\n",
    "\n",
    "Spark can work with data located on HDFS or a non-distributed filesystem. It can also use YARN from Hadoop, or [Mesos](https://mesos.apache.org/), or a resource manager of its own.\n",
    "\n",
    "All distributed operations with Spark are done using so-called Spark Session. Usually one is already created by your cluster's administrator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark1 = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cluster-444c-m.europe-west4-a.c.tactical-racer-294709.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbd9aecc710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark1.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "drwx------   - mapred hadoop          0 2020-11-26 12:44 /hadoop\r\n",
      "drwxrwxrwt   - hdfs   hadoop          0 2020-11-26 12:44 /tmp\r\n",
      "drwxrwxrwt   - hdfs   hadoop          0 2020-11-26 13:09 /user\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cluster-444c-m.europe-west4-a.c.tactical-racer-294709.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fafc55ad710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data\n",
    "\n",
    "Spark can consume data in a variety of formats, e.g. in JSON. We use the [YELP Dataset](https://www.yelp.com/dataset) for this example. It's easily obtainable and free to use in education and research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_on_hdfs = \"/user/borisshminke/data/yelp_academic_dataset_review.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 ms, sys: 6.51 ms, total: 8.54 ms\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark.read.text(reviews_on_hdfs).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"review_id\":\"xQY...|\n",
      "|{\"review_id\":\"UmF...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "some = spark.read.text(reviews_on_hdfs)\n",
    "some.show(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code simply reads a JSON file as a text, line by line, and counts the number of lines. Let's compare the speed with `wc` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8021122 /home/borisshminke/Downloads/yelp_academic_dataset_review.json\n",
      "CPU times: user 70.3 ms, sys: 8.76 ms, total: 79.1 ms\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!wc -l /home/borisshminke/Downloads/yelp_academic_dataset_review.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although `wc` is implemented in C and is more efficient in general than JVM code behind Spark, it uses only one CPU, and sometimes may work slower than it's distributed counterpart from Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing JSON in Spark is really simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|-MhfebM0QIsKt87iD...|   0|2015-04-15 05:21:16|    0|xQY8N_XvtGbearJ5X...|  2.0|As someone who ha...|     5|OwjRMXRC0KyPrIlcj...|\n",
      "|lbrU8StCq3yDfr-QM...|   0|2013-12-07 03:16:52|    1|UmFMZ8PyXZTY2Qcwz...|  1.0|I am actually hor...|     1|nIJD_7ZXHq-FX8byP...|\n",
      "|HQl28KMwrEKHqhFrr...|   0|2015-12-05 03:18:11|    0|LG2ZaYiOgpr2DK_90...|  5.0|I love Deagan's. ...|     1|V34qejxNsCbcgD8C0...|\n",
      "|5JxlZaqCnk1MnbgRi...|   0|2011-05-27 05:30:52|    0|i6g_oA9Yf9Y31qt0w...|  1.0|Dismal, lukewarm,...|     0|ofKDkJKXSKZXu5xJN...|\n",
      "|IS4cv902ykd8wj1TR...|   0|2017-01-14 21:56:57|    0|6TdNDKywdbjoTkize...|  4.0|Oh happy day, fin...|     0|UgMW8bLE0QMJDCkQ1...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.json(reviews_on_hdfs)\n",
    "reviews.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as sf\n",
    "\n",
    "x = reviews \\\n",
    "    .groupby(sf.date_trunc(\"day\", \"date\").alias(\"day\")) \\\n",
    "    .agg(sf.sum(\"cool\").alias(\"total_cool\")) \\\n",
    "    .sort(sf.desc(\"total_cool\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|                day|total_cool|\n",
      "+-------------------+----------+\n",
      "|2019-02-17 00:00:00|      4915|\n",
      "|2018-08-05 00:00:00|      4737|\n",
      "|2017-08-12 00:00:00|      4698|\n",
      "|2018-03-11 00:00:00|      4696|\n",
      "|2018-07-07 00:00:00|      4661|\n",
      "+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark can be used similarly to Pandas\n",
    "\n",
    "from pyspark.sql import functions as sf\n",
    "\n",
    "(\n",
    "    reviews\n",
    "    .select(sf.col(\"cool\").alias(\"groovy\"), \"date\")\n",
    "    .groupby(sf.date_trunc(\"day\", \"date\").alias(\"day\"))\n",
    "    .agg(\n",
    "        sf.count(sf.col(\"groovy\")).alias(\"total_cool\")\n",
    "    )\n",
    "    .sort(sf.desc(\"total_cool\"))\n",
    "    .show(n=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|                day|total_cool|\n",
      "+-------------------+----------+\n",
      "|2019-01-06 00:00:00|      3133|\n",
      "|2019-01-02 00:00:00|      3017|\n",
      "|2018-04-09 00:00:00|      2897|\n",
      "|2018-03-13 00:00:00|      2810|\n",
      "|2018-04-23 00:00:00|      2709|\n",
      "+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or you can use Spark as an SQL engine\n",
    "\n",
    "reviews.createOrReplaceTempView(\"reviews\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    date_trunc('day', date) AS day,\n",
    "    SUM(cool) AS total_cool\n",
    "FROM reviews\n",
    "GROUP BY\n",
    "    day\n",
    "ORDER BY\n",
    "    total_cool DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do It Yourself\n",
    "\n",
    "[Spark Manual](http://spark.apache.org/docs/2.4.3/api/python/index.html) is your best friend!\n",
    "\n",
    "* count number of users, buisenesses\n",
    "* count average number of reviews and stars per business and per user\n",
    "* find histograms for distributions of cool, funny, and useful columns\n",
    "* find ten most frequent words from the reviews\n",
    "* save results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id',\n",
       " 'cool',\n",
       " 'date',\n",
       " 'funny',\n",
       " 'review_id',\n",
       " 'stars',\n",
       " 'text',\n",
       " 'useful',\n",
       " 'user_id']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = reviews.select(\"user_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action\n",
    "\n",
    "count, show, top, max, min - computation happens\n",
    "\n",
    "# Transformations\n",
    "\n",
    "whatever - computation doesn't happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.select(sf.col(\"user_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.5 ms, sys: 1.43 ms, total: 8.92 ms\n",
      "Wall time: 27.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 ms, sys: 279 µs, total: 1.75 ms\n",
      "Wall time: 257 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = reviews.select(\"user_id\").distinct().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.75 ms, total: 3.75 ms\n",
      "Wall time: 7.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1968703"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "users.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 ms, sys: 0 ns, total: 2.56 ms\n",
      "Wall time: 443 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1968703"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "users.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "InMemoryTableScan [user_id#30]\n",
      "   +- InMemoryRelation [user_id#30], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- *(2) HashAggregate(keys=[user_id#30], functions=[])\n",
      "            +- Exchange hashpartitioning(user_id#30, 200)\n",
      "               +- *(1) HashAggregate(keys=[user_id#30], functions=[])\n",
      "                  +- InMemoryTableScan [user_id#30]\n",
      "                        +- InMemoryRelation [business_id#22, cool#23L, date#24, funny#25L, review_id#26, stars#27, text#28, useful#29L, user_id#30], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                              +- *(1) FileScan json [business_id#22,cool#23L,date#24,funny#25L,review_id#26,stars#27,text#28,useful#29L,user_id#30] Batched: false, Format: JSON, Location: InMemoryFileIndex[hdfs://cluster-444c-m/user/borisshminke/data/yelp_academic_dataset_review.json], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<business_id:string,cool:bigint,date:string,funny:bigint,review_id:string,stars:double,text...\n"
     ]
    }
   ],
   "source": [
    "users.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(distinct_users=1910451)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    reviews\n",
    "    .agg(sf.approx_count_distinct(reviews.user_id).alias('distinct_users'))\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               words|\n",
      "+--------------------+\n",
      "|[As, someone, who...|\n",
      "|[I, am, actually,...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.select(\n",
    "    sf.split(sf.col(\"text\"), \" \").alias(\"words\")\n",
    ").show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   word|\n",
      "+-------+\n",
      "|     As|\n",
      "|someone|\n",
      "|    who|\n",
      "|    has|\n",
      "| worked|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    reviews.select(\n",
    "        sf.split(sf.col(\"text\"), \" \").alias(\"words\")\n",
    "    )\n",
    "    .select(\n",
    "        sf.explode(\"words\").alias(\"word\")\n",
    "    )\n",
    ").show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|word|     cnt|\n",
      "+----+--------+\n",
      "|    |13151079|\n",
      "|  in| 9041099|\n",
      "|  it| 7460125|\n",
      "|  my| 7109453|\n",
      "|with| 6964448|\n",
      "|that| 6752534|\n",
      "| The| 6302953|\n",
      "| but| 5685251|\n",
      "|  on| 5678107|\n",
      "|have| 5335047|\n",
      "+----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    reviews.select(\n",
    "        sf.split(sf.col(\"text\"), \" \").alias(\"words\")\n",
    "    )\n",
    "    .filter(\"stars > 4\")\n",
    "    .select(\n",
    "        sf.explode(\"words\").alias(\"word\")\n",
    "    )\n",
    "    .cache()\n",
    "    .filter(\"word NOT IN ('the', 'and', 'to', 'I', 'a', 'was', 'of', 'is', 'for')\")\n",
    "    .groupby(\n",
    "        \"word\"\n",
    "    )\n",
    "    .agg(sf.count(\"word\").alias(\"cnt\"))\n",
    "    .sort(sf.desc(\"cnt\"))\n",
    "    .show(n=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 0))\n",
      "\n"
     ]
    },
    {
     "ename": "ParseException",
     "evalue": "u\"\\nextraneous input '\\xb4' expecting {')', ','}(line 3, pos 27)\\n\\n== SQL ==\\n\\nSELECT\\n    explode(split(text, ' '\\xb4)) AS word,\\n---------------------------^^^\\n    COUNT(*) cnt\\nFROM reviews\\nGROUP BY\\n    word\\nORDER BY\\n    cnt DESC\\nLIMIT 5\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mParseException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-23b155fc0ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0mDESC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mLIMIT\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \"\"\").show()\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.pyc\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \"\"\"\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.parser.ParseException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.streaming.StreamingQueryException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStreamingQueryException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParseException\u001b[0m: u\"\\nextraneous input '\\xb4' expecting {')', ','}(line 3, pos 27)\\n\\n== SQL ==\\n\\nSELECT\\n    explode(split(text, ' '\\xb4)) AS word,\\n---------------------------^^^\\n    COUNT(*) cnt\\nFROM reviews\\nGROUP BY\\n    word\\nORDER BY\\n    cnt DESC\\nLIMIT 5\\n\""
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    explode(split(text, ' '´)) AS word,\n",
    "    COUNT(*) cnt\n",
    "FROM reviews\n",
    "GROUP BY\n",
    "    word\n",
    "ORDER BY\n",
    "    cnt DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.write.csv(\"/user/borisshminke/data/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 201 items\r\n",
      "-rw-r--r--   2 root hadoop          0 2020-11-26 15:12 /user/borisshminke/data/users/_SUCCESS\r\n",
      "-rw-r--r--   2 root hadoop     229540 2020-11-26 15:12 /user/borisshminke/data/users/part-00000-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227516 2020-11-26 15:12 /user/borisshminke/data/users/part-00001-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224894 2020-11-26 15:12 /user/borisshminke/data/users/part-00002-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226021 2020-11-26 15:12 /user/borisshminke/data/users/part-00003-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222042 2020-11-26 15:12 /user/borisshminke/data/users/part-00004-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225331 2020-11-26 15:12 /user/borisshminke/data/users/part-00005-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225492 2020-11-26 15:12 /user/borisshminke/data/users/part-00006-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223859 2020-11-26 15:12 /user/borisshminke/data/users/part-00007-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223721 2020-11-26 15:12 /user/borisshminke/data/users/part-00008-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226757 2020-11-26 15:12 /user/borisshminke/data/users/part-00009-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225768 2020-11-26 15:12 /user/borisshminke/data/users/part-00010-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230023 2020-11-26 15:12 /user/borisshminke/data/users/part-00011-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229793 2020-11-26 15:12 /user/borisshminke/data/users/part-00012-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230023 2020-11-26 15:12 /user/borisshminke/data/users/part-00013-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225262 2020-11-26 15:12 /user/borisshminke/data/users/part-00014-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225308 2020-11-26 15:12 /user/borisshminke/data/users/part-00015-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226895 2020-11-26 15:12 /user/borisshminke/data/users/part-00016-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224204 2020-11-26 15:12 /user/borisshminke/data/users/part-00017-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223284 2020-11-26 15:12 /user/borisshminke/data/users/part-00018-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230161 2020-11-26 15:12 /user/borisshminke/data/users/part-00019-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226136 2020-11-26 15:12 /user/borisshminke/data/users/part-00020-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230805 2020-11-26 15:12 /user/borisshminke/data/users/part-00021-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227470 2020-11-26 15:12 /user/borisshminke/data/users/part-00022-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228643 2020-11-26 15:12 /user/borisshminke/data/users/part-00023-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223399 2020-11-26 15:12 /user/borisshminke/data/users/part-00024-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229724 2020-11-26 15:12 /user/borisshminke/data/users/part-00025-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225745 2020-11-26 15:12 /user/borisshminke/data/users/part-00026-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225331 2020-11-26 15:12 /user/borisshminke/data/users/part-00027-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226642 2020-11-26 15:12 /user/borisshminke/data/users/part-00028-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224963 2020-11-26 15:12 /user/borisshminke/data/users/part-00029-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226205 2020-11-26 15:12 /user/borisshminke/data/users/part-00030-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230391 2020-11-26 15:12 /user/borisshminke/data/users/part-00031-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223606 2020-11-26 15:12 /user/borisshminke/data/users/part-00032-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227125 2020-11-26 15:12 /user/borisshminke/data/users/part-00033-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222088 2020-11-26 15:12 /user/borisshminke/data/users/part-00034-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225285 2020-11-26 15:12 /user/borisshminke/data/users/part-00035-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226642 2020-11-26 15:12 /user/borisshminke/data/users/part-00036-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225768 2020-11-26 15:12 /user/borisshminke/data/users/part-00037-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227539 2020-11-26 15:12 /user/borisshminke/data/users/part-00038-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228850 2020-11-26 15:12 /user/borisshminke/data/users/part-00039-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226182 2020-11-26 15:12 /user/borisshminke/data/users/part-00040-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222778 2020-11-26 15:12 /user/borisshminke/data/users/part-00041-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227355 2020-11-26 15:12 /user/borisshminke/data/users/part-00042-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226826 2020-11-26 15:12 /user/borisshminke/data/users/part-00043-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226090 2020-11-26 15:12 /user/borisshminke/data/users/part-00044-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     231748 2020-11-26 15:12 /user/borisshminke/data/users/part-00045-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222847 2020-11-26 15:12 /user/borisshminke/data/users/part-00046-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227907 2020-11-26 15:12 /user/borisshminke/data/users/part-00047-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228298 2020-11-26 15:12 /user/borisshminke/data/users/part-00048-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227263 2020-11-26 15:12 /user/borisshminke/data/users/part-00049-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223307 2020-11-26 15:12 /user/borisshminke/data/users/part-00050-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222686 2020-11-26 15:12 /user/borisshminke/data/users/part-00051-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227654 2020-11-26 15:12 /user/borisshminke/data/users/part-00052-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     221973 2020-11-26 15:12 /user/borisshminke/data/users/part-00053-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224388 2020-11-26 15:12 /user/borisshminke/data/users/part-00054-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228689 2020-11-26 15:12 /user/borisshminke/data/users/part-00055-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222847 2020-11-26 15:12 /user/borisshminke/data/users/part-00056-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223284 2020-11-26 15:12 /user/borisshminke/data/users/part-00057-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228298 2020-11-26 15:12 /user/borisshminke/data/users/part-00058-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225492 2020-11-26 15:12 /user/borisshminke/data/users/part-00059-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225837 2020-11-26 15:12 /user/borisshminke/data/users/part-00060-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228275 2020-11-26 15:12 /user/borisshminke/data/users/part-00061-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228988 2020-11-26 15:12 /user/borisshminke/data/users/part-00062-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229701 2020-11-26 15:12 /user/borisshminke/data/users/part-00063-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226550 2020-11-26 15:12 /user/borisshminke/data/users/part-00064-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     219719 2020-11-26 15:12 /user/borisshminke/data/users/part-00065-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229011 2020-11-26 15:12 /user/borisshminke/data/users/part-00066-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224802 2020-11-26 15:12 /user/borisshminke/data/users/part-00067-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225193 2020-11-26 15:12 /user/borisshminke/data/users/part-00068-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229057 2020-11-26 15:12 /user/borisshminke/data/users/part-00069-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225630 2020-11-26 15:12 /user/borisshminke/data/users/part-00070-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228873 2020-11-26 15:12 /user/borisshminke/data/users/part-00071-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230621 2020-11-26 15:12 /user/borisshminke/data/users/part-00072-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227125 2020-11-26 15:12 /user/borisshminke/data/users/part-00073-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224986 2020-11-26 15:12 /user/borisshminke/data/users/part-00074-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227125 2020-11-26 15:12 /user/borisshminke/data/users/part-00075-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225377 2020-11-26 15:12 /user/borisshminke/data/users/part-00076-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223813 2020-11-26 15:12 /user/borisshminke/data/users/part-00077-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227355 2020-11-26 15:12 /user/borisshminke/data/users/part-00078-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227470 2020-11-26 15:12 /user/borisshminke/data/users/part-00079-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226205 2020-11-26 15:12 /user/borisshminke/data/users/part-00080-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224618 2020-11-26 15:12 /user/borisshminke/data/users/part-00081-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228252 2020-11-26 15:12 /user/borisshminke/data/users/part-00082-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230023 2020-11-26 15:12 /user/borisshminke/data/users/part-00083-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226527 2020-11-26 15:12 /user/borisshminke/data/users/part-00084-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225538 2020-11-26 15:12 /user/borisshminke/data/users/part-00085-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228896 2020-11-26 15:12 /user/borisshminke/data/users/part-00086-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227700 2020-11-26 15:12 /user/borisshminke/data/users/part-00087-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226021 2020-11-26 15:12 /user/borisshminke/data/users/part-00088-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225630 2020-11-26 15:12 /user/borisshminke/data/users/part-00089-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225331 2020-11-26 15:12 /user/borisshminke/data/users/part-00090-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224457 2020-11-26 15:12 /user/borisshminke/data/users/part-00091-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224480 2020-11-26 15:12 /user/borisshminke/data/users/part-00092-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222663 2020-11-26 15:12 /user/borisshminke/data/users/part-00093-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223445 2020-11-26 15:12 /user/borisshminke/data/users/part-00094-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226550 2020-11-26 15:12 /user/borisshminke/data/users/part-00095-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230828 2020-11-26 15:12 /user/borisshminke/data/users/part-00096-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222272 2020-11-26 15:12 /user/borisshminke/data/users/part-00097-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222778 2020-11-26 15:12 /user/borisshminke/data/users/part-00098-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228528 2020-11-26 15:12 /user/borisshminke/data/users/part-00099-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225032 2020-11-26 15:12 /user/borisshminke/data/users/part-00100-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     231035 2020-11-26 15:12 /user/borisshminke/data/users/part-00101-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224227 2020-11-26 15:12 /user/borisshminke/data/users/part-00102-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225952 2020-11-26 15:12 /user/borisshminke/data/users/part-00103-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226274 2020-11-26 15:12 /user/borisshminke/data/users/part-00104-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224181 2020-11-26 15:12 /user/borisshminke/data/users/part-00105-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227286 2020-11-26 15:12 /user/borisshminke/data/users/part-00106-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228827 2020-11-26 15:12 /user/borisshminke/data/users/part-00107-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229977 2020-11-26 15:12 /user/borisshminke/data/users/part-00108-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223997 2020-11-26 15:12 /user/borisshminke/data/users/part-00109-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224618 2020-11-26 15:12 /user/borisshminke/data/users/part-00110-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225009 2020-11-26 15:12 /user/borisshminke/data/users/part-00111-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230989 2020-11-26 15:12 /user/borisshminke/data/users/part-00112-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225998 2020-11-26 15:12 /user/borisshminke/data/users/part-00113-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227125 2020-11-26 15:12 /user/borisshminke/data/users/part-00114-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229034 2020-11-26 15:12 /user/borisshminke/data/users/part-00115-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     221766 2020-11-26 15:12 /user/borisshminke/data/users/part-00116-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226734 2020-11-26 15:12 /user/borisshminke/data/users/part-00117-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224802 2020-11-26 15:12 /user/borisshminke/data/users/part-00118-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226343 2020-11-26 15:12 /user/borisshminke/data/users/part-00119-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226159 2020-11-26 15:12 /user/borisshminke/data/users/part-00120-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227286 2020-11-26 15:12 /user/borisshminke/data/users/part-00121-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225975 2020-11-26 15:12 /user/borisshminke/data/users/part-00122-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225653 2020-11-26 15:12 /user/borisshminke/data/users/part-00123-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229241 2020-11-26 15:12 /user/borisshminke/data/users/part-00124-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227424 2020-11-26 15:12 /user/borisshminke/data/users/part-00125-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     231012 2020-11-26 15:12 /user/borisshminke/data/users/part-00126-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226895 2020-11-26 15:12 /user/borisshminke/data/users/part-00127-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226665 2020-11-26 15:12 /user/borisshminke/data/users/part-00128-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225630 2020-11-26 15:12 /user/borisshminke/data/users/part-00129-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227056 2020-11-26 15:12 /user/borisshminke/data/users/part-00130-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225285 2020-11-26 15:12 /user/borisshminke/data/users/part-00131-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222387 2020-11-26 15:12 /user/borisshminke/data/users/part-00132-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224457 2020-11-26 15:12 /user/borisshminke/data/users/part-00133-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227194 2020-11-26 15:12 /user/borisshminke/data/users/part-00134-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222709 2020-11-26 15:12 /user/borisshminke/data/users/part-00135-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227148 2020-11-26 15:12 /user/borisshminke/data/users/part-00136-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226596 2020-11-26 15:12 /user/borisshminke/data/users/part-00137-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227332 2020-11-26 15:12 /user/borisshminke/data/users/part-00138-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225032 2020-11-26 15:12 /user/borisshminke/data/users/part-00139-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222640 2020-11-26 15:12 /user/borisshminke/data/users/part-00140-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225423 2020-11-26 15:12 /user/borisshminke/data/users/part-00141-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226205 2020-11-26 15:12 /user/borisshminke/data/users/part-00142-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222893 2020-11-26 15:12 /user/borisshminke/data/users/part-00143-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225170 2020-11-26 15:12 /user/borisshminke/data/users/part-00144-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229494 2020-11-26 15:12 /user/borisshminke/data/users/part-00145-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224480 2020-11-26 15:12 /user/borisshminke/data/users/part-00146-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225400 2020-11-26 15:12 /user/borisshminke/data/users/part-00147-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226021 2020-11-26 15:12 /user/borisshminke/data/users/part-00148-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229057 2020-11-26 15:12 /user/borisshminke/data/users/part-00149-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226895 2020-11-26 15:12 /user/borisshminke/data/users/part-00150-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228137 2020-11-26 15:12 /user/borisshminke/data/users/part-00151-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228505 2020-11-26 15:12 /user/borisshminke/data/users/part-00152-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229701 2020-11-26 15:12 /user/borisshminke/data/users/part-00153-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226780 2020-11-26 15:12 /user/borisshminke/data/users/part-00154-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225607 2020-11-26 15:12 /user/borisshminke/data/users/part-00155-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226113 2020-11-26 15:12 /user/borisshminke/data/users/part-00156-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229379 2020-11-26 15:12 /user/borisshminke/data/users/part-00157-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223169 2020-11-26 15:12 /user/borisshminke/data/users/part-00158-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   2 root hadoop     229724 2020-11-26 15:12 /user/borisshminke/data/users/part-00159-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225216 2020-11-26 15:12 /user/borisshminke/data/users/part-00160-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227010 2020-11-26 15:12 /user/borisshminke/data/users/part-00161-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226389 2020-11-26 15:12 /user/borisshminke/data/users/part-00162-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228965 2020-11-26 15:12 /user/borisshminke/data/users/part-00163-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228942 2020-11-26 15:12 /user/borisshminke/data/users/part-00164-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     231541 2020-11-26 15:12 /user/borisshminke/data/users/part-00165-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224020 2020-11-26 15:12 /user/borisshminke/data/users/part-00166-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     221835 2020-11-26 15:12 /user/borisshminke/data/users/part-00167-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223192 2020-11-26 15:12 /user/borisshminke/data/users/part-00168-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     231518 2020-11-26 15:12 /user/borisshminke/data/users/part-00169-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224342 2020-11-26 15:12 /user/borisshminke/data/users/part-00170-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226711 2020-11-26 15:12 /user/borisshminke/data/users/part-00171-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224986 2020-11-26 15:12 /user/borisshminke/data/users/part-00172-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223100 2020-11-26 15:12 /user/borisshminke/data/users/part-00173-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226320 2020-11-26 15:12 /user/borisshminke/data/users/part-00174-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225607 2020-11-26 15:12 /user/borisshminke/data/users/part-00175-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224687 2020-11-26 15:12 /user/borisshminke/data/users/part-00176-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230414 2020-11-26 15:12 /user/borisshminke/data/users/part-00177-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     230000 2020-11-26 15:12 /user/borisshminke/data/users/part-00178-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224710 2020-11-26 15:12 /user/borisshminke/data/users/part-00179-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     224457 2020-11-26 15:12 /user/borisshminke/data/users/part-00180-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227792 2020-11-26 15:12 /user/borisshminke/data/users/part-00181-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226435 2020-11-26 15:12 /user/borisshminke/data/users/part-00182-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228367 2020-11-26 15:12 /user/borisshminke/data/users/part-00183-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     223859 2020-11-26 15:12 /user/borisshminke/data/users/part-00184-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228735 2020-11-26 15:12 /user/borisshminke/data/users/part-00185-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225653 2020-11-26 15:12 /user/borisshminke/data/users/part-00186-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     221283 2020-11-26 15:12 /user/borisshminke/data/users/part-00187-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225860 2020-11-26 15:12 /user/borisshminke/data/users/part-00188-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227631 2020-11-26 15:12 /user/borisshminke/data/users/part-00189-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226987 2020-11-26 15:12 /user/borisshminke/data/users/part-00190-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     225860 2020-11-26 15:12 /user/borisshminke/data/users/part-00191-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     231219 2020-11-26 15:12 /user/borisshminke/data/users/part-00192-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     222571 2020-11-26 15:12 /user/borisshminke/data/users/part-00193-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226205 2020-11-26 15:12 /user/borisshminke/data/users/part-00194-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     226044 2020-11-26 15:12 /user/borisshminke/data/users/part-00195-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228620 2020-11-26 15:12 /user/borisshminke/data/users/part-00196-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     228482 2020-11-26 15:12 /user/borisshminke/data/users/part-00197-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     227217 2020-11-26 15:12 /user/borisshminke/data/users/part-00198-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n",
      "-rw-r--r--   2 root hadoop     229839 2020-11-26 15:12 /user/borisshminke/data/users/part-00199-df5777f8-9c80-400d-b56b-552b22216437-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/borisshminke/data/users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = spark.read.csv(\"/user/borisshminke/data/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|iAevEfcmtCr2cpd6I...|\n",
      "|h-Zj9GUJvErqVOw-K...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -getmerge /user/borisshminke/data/users /home/borisshminke/Downloads/users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KWFiZKiZBANVxuhm4MLBNw\r\n",
      "VmYpF5C3GL-7wFnvOkhpvg\r\n",
      "1Dul59QEe-Q-7OQHTLOptw\r\n",
      "xS6kmkMXp0PRrFwkSWq2-w\r\n",
      "j56G3m8vYtA_2Io6FcISBg\r\n",
      "ruHz-qN-j21kg0iyIgGE9Q\r\n",
      "M6-A6F0B3kM5i94Kr0XHcw\r\n",
      "z2Gi5vo-8j544qN_g6ziEg\r\n",
      "CzkWUMIYDxUSetfCRvYG5g\r\n",
      "Uf_TVv1Z4s024jdI4UKWtA\r\n"
     ]
    }
   ],
   "source": [
    "!head /home/borisshminke/Downloads/users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
