{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Kafka\n",
    "\n",
    "There exists a neat Python package for communicating with a running Kafka cluster. You can even admin the cluster using it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteTopicsResponse_v3(throttle_time_ms=0, topic_error_codes=[(topic='main_topic', error_code=0)])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kafka import KafkaAdminClient\n",
    "\n",
    "admin_client = KafkaAdminClient()\n",
    "admin_client.delete_topics(admin_client.list_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Data to Kafka\n",
    "\n",
    "If you write some data to a non-existent topic, it's been created automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['main_topic']\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "\n",
    "print(admin_client.list_topics())\n",
    "MAIN_TOPIC = \"main_topic\"\n",
    "producer = KafkaProducer()\n",
    "for i in range(10):\n",
    "    producer.send(MAIN_TOPIC, bytes(str(i), encoding=\"utf-8\"))\n",
    "print(admin_client.list_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data from Kafka\n",
    "\n",
    "Reading is done with a consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics, Partitions, and Offsets\n",
    "\n",
    "Messages in Kafka are organised into topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main_topic'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer.topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic can have several partitions with different starting and ending offsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{TopicPartition(topic='main_topic', partition=0): 0}\n",
      "{TopicPartition(topic='main_topic', partition=0): 10}\n"
     ]
    }
   ],
   "source": [
    "from kafka import TopicPartition\n",
    "\n",
    "partitions = [\n",
    "    TopicPartition(MAIN_TOPIC, partition)\n",
    "    for partition in consumer.partitions_for_topic(MAIN_TOPIC)\n",
    "]\n",
    "print(consumer.beginning_offsets(partitions))\n",
    "print(consumer.end_offsets(partitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reading something from Kafka, one should assign the consumer to a topic and partition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from a given offset of a partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.assign(partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can read from any offset of the partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(consumer.position(partitions[0]))\n",
    "consumer.seek(partitions[0], 0)\n",
    "print(consumer.position(partitions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data can be done by batches of any desired size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0'\n",
      "b'1'\n",
      "b'2'\n",
      "b'3'\n",
      "b'4'\n",
      "b'5'\n",
      "b'6'\n",
      "b'7'\n",
      "b'8'\n",
      "b'9'\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    data = consumer.poll(\n",
    "        timeout_ms=10,\n",
    "        max_records=1\n",
    "    )[partitions[0]][0].value\n",
    "    print(data)\n",
    "print(consumer.position(partitions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
