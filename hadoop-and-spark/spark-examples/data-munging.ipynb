{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session\n",
    "\n",
    "Spark can work with data located on HDFS or a non-distributed filesystem. It can also use YARN from Hadoop, or [Mesos](https://mesos.apache.org/), or a resource manager of its own. For this example we use the last option.\n",
    "\n",
    "All distributed operations with Spark are done using so-called Spark Session. Let's create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://math10.unice.fr:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9f15244d90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"400g\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we limit an amount of memory used to prevent Spark trying to eat all the server. Configuring Spark might be tricky at times. When you work on a dedicated Spark cluster, your admin will probably create a session for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data\n",
    "\n",
    "Spark can consume data in a variety of formats, e.g. in JSON. We use the [YELP Dataset](https://www.yelp.com/dataset) for this example. It's easily obtainable and free to use in education and research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.3 ms, sys: 7.89 ms, total: 33.2 ms\n",
      "Wall time: 4.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark.read.text(\"/workdir/boris/data/yelp_dataset/yelp_academic_dataset_review.json\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code simply reads a JSON file as a text, line by line, and counts the number of lines. Let's compare the speed with `wc` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8021122 /workdir/boris/data/yelp_dataset/yelp_academic_dataset_review.json\r\n",
      "wc -l /workdir/boris/data/yelp_dataset/yelp_academic_dataset_review.json  0,30s user 2,02s system 99% cpu 2,323 total\r\n"
     ]
    }
   ],
   "source": [
    "!time wc -l /workdir/boris/data/yelp_dataset/yelp_academic_dataset_review.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although `wc` is implemented in C and is more efficient in general than JVM code behind Spark, it uses only one CPU, thus working several times slower than it's distributed counterpart from Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing JSON in Spark is really simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|-MhfebM0QIsKt87iD...|   0|2015-04-15 05:21:16|    0|xQY8N_XvtGbearJ5X...|  2.0|As someone who ha...|     5|OwjRMXRC0KyPrIlcj...|\n",
      "|lbrU8StCq3yDfr-QM...|   0|2013-12-07 03:16:52|    1|UmFMZ8PyXZTY2Qcwz...|  1.0|I am actually hor...|     1|nIJD_7ZXHq-FX8byP...|\n",
      "|HQl28KMwrEKHqhFrr...|   0|2015-12-05 03:18:11|    0|LG2ZaYiOgpr2DK_90...|  5.0|I love Deagan's. ...|     1|V34qejxNsCbcgD8C0...|\n",
      "|5JxlZaqCnk1MnbgRi...|   0|2011-05-27 05:30:52|    0|i6g_oA9Yf9Y31qt0w...|  1.0|Dismal, lukewarm,...|     0|ofKDkJKXSKZXu5xJN...|\n",
      "|IS4cv902ykd8wj1TR...|   0|2017-01-14 21:56:57|    0|6TdNDKywdbjoTkize...|  4.0|Oh happy day, fin...|     0|UgMW8bLE0QMJDCkQ1...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.json(\n",
    "    \"/workdir/boris/data/yelp_dataset/yelp_academic_dataset_review.json\"\n",
    ")\n",
    "reviews.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is quite large, about 6GB. If you have only a handful CPUs, you'd like to use method [sample](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=sample#pyspark.sql.DataFrame.sample) after reading the JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data\n",
    "\n",
    "Spark has a vast library of feature engineering functions. For example, we can get TF-IDF representation for our review corpus. In the following snippet we construct a data preparation pipeline with three stages:\n",
    "1. we get review text parsed into words\n",
    "1. we count term frequencies of our bags of words\n",
    "1. we normalise by inverted document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|      term_frequency|           embedding|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|As someone who ha...|[as, someone, who...|(262144,[991,1578...|(262144,[991,1578...|\n",
      "|I am actually hor...|[i, am, actually,...|(262144,[1619,296...|(262144,[1619,296...|\n",
      "|I love Deagan's. ...|[i, love, deagan'...|(262144,[9698,135...|(262144,[9698,135...|\n",
      "|Dismal, lukewarm,...|[dismal,, lukewar...|(262144,[4106,462...|(262144,[4106,462...|\n",
      "|Oh happy day, fin...|[oh, happy, day,,...|(262144,[2701,425...|(262144,[2701,425...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 694 ms, sys: 487 ms, total: 1.18 s\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "\n",
    "data_preparation = Pipeline(stages=[\n",
    "    Tokenizer(inputCol=\"text\", outputCol=\"words\"),\n",
    "    HashingTF(inputCol=\"words\", outputCol=\"term_frequency\"),\n",
    "    IDF(inputCol=\"term_frequency\", outputCol=\"embedding\")\n",
    "])\n",
    "prepared_reviews = data_preparation.fit(reviews).transform(reviews)\n",
    "prepared_reviews.select(\"text\", \"words\", \"term_frequency\", \"embedding\").show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into the details of the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text='As someone who has worked with many museums, I was eager to visit this gallery on my most recent trip to Las Vegas. When I saw they would be showing infamous eggs of the House of Faberge from the Virginia Museum of Fine Arts (VMFA), I knew I had to go!\\n\\nTucked away near the gelateria and the garden, the Gallery is pretty much hidden from view. It\\'s what real estate agents would call \"cozy\" or \"charming\" - basically any euphemism for small.\\n\\nThat being said, you can still see wonderful art at a gallery of any size, so why the two *s you ask? Let me tell you:\\n\\n* pricing for this, while relatively inexpensive for a Las Vegas attraction, is completely over the top. For the space and the amount of art you can fit in there, it is a bit much.\\n* it\\'s not kid friendly at all. Seriously, don\\'t bring them.\\n* the security is not trained properly for the show. When the curating and design teams collaborate for exhibitions, there is a definite flow. That means visitors should view the art in a certain sequence, whether it be by historical period or cultural significance (this is how audio guides are usually developed). When I arrived in the gallery I could not tell where to start, and security was certainly not helpful. I was told to \"just look around\" and \"do whatever.\" \\n\\nAt such a *fine* institution, I find the lack of knowledge and respect for the art appalling.', words=['as', 'someone', 'who', 'has', 'worked', 'with', 'many', 'museums,', 'i', 'was', 'eager', 'to', 'visit', 'this', 'gallery', 'on', 'my', 'most', 'recent', 'trip', 'to', 'las', 'vegas.', 'when', 'i', 'saw', 'they', 'would', 'be', 'showing', 'infamous', 'eggs', 'of', 'the', 'house', 'of', 'faberge', 'from', 'the', 'virginia', 'museum', 'of', 'fine', 'arts', '(vmfa),', 'i', 'knew', 'i', 'had', 'to', 'go!', '', 'tucked', 'away', 'near', 'the', 'gelateria', 'and', 'the', 'garden,', 'the', 'gallery', 'is', 'pretty', 'much', 'hidden', 'from', 'view.', \"it's\", 'what', 'real', 'estate', 'agents', 'would', 'call', '\"cozy\"', 'or', '\"charming\"', '-', 'basically', 'any', 'euphemism', 'for', 'small.', '', 'that', 'being', 'said,', 'you', 'can', 'still', 'see', 'wonderful', 'art', 'at', 'a', 'gallery', 'of', 'any', 'size,', 'so', 'why', 'the', 'two', '*s', 'you', 'ask?', 'let', 'me', 'tell', 'you:', '', '*', 'pricing', 'for', 'this,', 'while', 'relatively', 'inexpensive', 'for', 'a', 'las', 'vegas', 'attraction,', 'is', 'completely', 'over', 'the', 'top.', 'for', 'the', 'space', 'and', 'the', 'amount', 'of', 'art', 'you', 'can', 'fit', 'in', 'there,', 'it', 'is', 'a', 'bit', 'much.', '*', \"it's\", 'not', 'kid', 'friendly', 'at', 'all.', 'seriously,', \"don't\", 'bring', 'them.', '*', 'the', 'security', 'is', 'not', 'trained', 'properly', 'for', 'the', 'show.', 'when', 'the', 'curating', 'and', 'design', 'teams', 'collaborate', 'for', 'exhibitions,', 'there', 'is', 'a', 'definite', 'flow.', 'that', 'means', 'visitors', 'should', 'view', 'the', 'art', 'in', 'a', 'certain', 'sequence,', 'whether', 'it', 'be', 'by', 'historical', 'period', 'or', 'cultural', 'significance', '(this', 'is', 'how', 'audio', 'guides', 'are', 'usually', 'developed).', 'when', 'i', 'arrived', 'in', 'the', 'gallery', 'i', 'could', 'not', 'tell', 'where', 'to', 'start,', 'and', 'security', 'was', 'certainly', 'not', 'helpful.', 'i', 'was', 'told', 'to', '\"just', 'look', 'around\"', 'and', '\"do', 'whatever.\"', '', '', 'at', 'such', 'a', '*fine*', 'institution,', 'i', 'find', 'the', 'lack', 'of', 'knowledge', 'and', 'respect', 'for', 'the', 'art', 'appalling.'], term_frequency=SparseVector(262144, {991: 1.0, 1578: 1.0, 2432: 1.0, 4214: 1.0, 5451: 1.0, 7221: 1.0, 8287: 1.0, 8538: 1.0, 9129: 1.0, 10132: 1.0, 12035: 1.0, 15585: 1.0, 19036: 8.0, 20891: 1.0, 21312: 1.0, 23071: 1.0, 24980: 3.0, 27576: 5.0, 30121: 1.0, 30950: 2.0, 31536: 1.0, 34254: 1.0, 38640: 1.0, 39522: 1.0, 40268: 1.0, 45252: 1.0, 45595: 1.0, 48448: 2.0, 49013: 1.0, 50001: 1.0, 50230: 1.0, 51555: 1.0, 52788: 1.0, 52914: 1.0, 53512: 1.0, 54335: 1.0, 56998: 1.0, 58267: 1.0, 58672: 1.0, 60068: 1.0, 67416: 1.0, 71016: 1.0, 73342: 4.0, 74448: 1.0, 74944: 1.0, 75958: 1.0, 76764: 1.0, 77053: 2.0, 77073: 1.0, 77688: 1.0, 81566: 1.0, 82035: 4.0, 83820: 1.0, 84116: 1.0, 85530: 2.0, 86617: 1.0, 88813: 1.0, 91878: 1.0, 94935: 1.0, 95805: 2.0, 95889: 16.0, 99211: 3.0, 101169: 2.0, 106776: 7.0, 106841: 6.0, 107107: 6.0, 107553: 1.0, 108241: 1.0, 108437: 2.0, 108541: 1.0, 109706: 1.0, 110689: 1.0, 111823: 1.0, 114316: 1.0, 114318: 1.0, 115124: 1.0, 115736: 1.0, 116896: 1.0, 117491: 1.0, 118213: 1.0, 119453: 2.0, 124620: 1.0, 125257: 1.0, 126466: 1.0, 127653: 1.0, 132786: 1.0, 137765: 1.0, 137855: 2.0, 138141: 1.0, 143000: 1.0, 143741: 1.0, 145207: 2.0, 148039: 1.0, 149523: 1.0, 150278: 1.0, 151255: 1.0, 151536: 1.0, 153969: 1.0, 154637: 1.0, 155971: 1.0, 156637: 1.0, 158069: 1.0, 160078: 1.0, 160249: 1.0, 162991: 1.0, 165112: 1.0, 165395: 1.0, 168828: 1.0, 169901: 1.0, 173339: 1.0, 174475: 1.0, 177755: 1.0, 177813: 1.0, 179832: 1.0, 180008: 1.0, 183698: 1.0, 184046: 1.0, 187114: 3.0, 189082: 1.0, 191073: 1.0, 194186: 2.0, 196839: 1.0, 197443: 1.0, 198589: 1.0, 198783: 1.0, 199693: 1.0, 202290: 1.0, 206426: 1.0, 209596: 1.0, 211086: 1.0, 211756: 1.0, 214895: 1.0, 214962: 3.0, 215744: 1.0, 217856: 1.0, 219087: 6.0, 219915: 6.0, 221693: 4.0, 221938: 3.0, 223365: 1.0, 223763: 1.0, 227226: 1.0, 228250: 1.0, 228685: 1.0, 230689: 1.0, 230804: 1.0, 231919: 1.0, 234050: 1.0, 235273: 1.0, 235665: 1.0, 237499: 1.0, 240944: 1.0, 242794: 1.0, 243890: 1.0, 244714: 1.0, 245044: 1.0, 245415: 1.0, 245951: 1.0, 247372: 1.0, 249180: 5.0, 249598: 1.0, 250421: 1.0, 250855: 3.0, 251302: 1.0, 251390: 2.0, 253178: 1.0, 257091: 1.0, 258728: 1.0, 261754: 1.0}), embedding=SparseVector(262144, {991: 3.9667, 1578: 4.1929, 2432: 9.1654, 4214: 3.7445, 5451: 5.1935, 7221: 1.9584, 8287: 3.8164, 8538: 2.5519, 9129: 3.3122, 10132: 9.246, 12035: 4.4804, 15585: 3.7118, 19036: 2.6412, 20891: 3.9601, 21312: 8.6462, 23071: 2.4314, 24980: 4.5475, 27576: 1.4764, 30121: 4.4851, 30950: 1.379, 31536: 2.5076, 34254: 7.5284, 38640: 2.5126, 39522: 6.5649, 40268: 5.5857, 45252: 4.3561, 45595: 8.5062, 48448: 1.7935, 49013: 2.8939, 50001: 1.5332, 50230: 10.9488, 51555: 5.4738, 52788: 4.5191, 52914: 2.694, 53512: 5.9853, 54335: 10.3331, 56998: 4.1771, 58267: 1.0925, 58672: 2.2073, 60068: 5.9113, 67416: 0.8758, 71016: 5.62, 73342: 21.428, 74448: 4.4384, 74944: 3.1648, 75958: 2.7596, 76764: 2.2907, 77053: 4.7909, 77073: 3.7999, 77688: 6.1837, 81566: 1.7314, 82035: 19.2396, 83820: 6.3732, 84116: 7.4133, 85530: 6.553, 86617: 5.5783, 88813: 4.5041, 91878: 2.7262, 94935: 10.7916, 95805: 3.3885, 95889: 1.7454, 99211: 1.5451, 101169: 2.9986, 106776: 3.5833, 106841: 3.2412, 107107: 1.5367, 107553: 11.2924, 108241: 3.2333, 108437: 3.7142, 108541: 0.6914, 109706: 3.3041, 110689: 4.5884, 111823: 7.8839, 114316: 9.9418, 114318: 4.401, 115124: 6.2331, 115736: 5.8397, 116896: 8.0876, 117491: 1.0482, 118213: 5.7416, 119453: 3.2317, 124620: 7.8846, 125257: 9.559, 126466: 0.7639, 127653: 5.3308, 132786: 1.9981, 137765: 2.7788, 137855: 3.0938, 138141: 7.2299, 143000: 5.0037, 143741: 2.3633, 145207: 2.2683, 148039: 2.6427, 149523: 5.212, 150278: 4.0379, 151255: 6.397, 151536: 0.84, 153969: 4.5631, 154637: 3.5106, 155971: 6.2445, 156637: 8.5464, 158069: 4.9166, 160078: 7.6761, 160249: 2.6506, 162991: 5.0549, 165112: 5.8341, 165395: 11.3543, 168828: 4.9336, 169901: 2.5963, 173339: 3.2242, 174475: 3.7786, 177755: 9.4663, 177813: 11.1791, 179832: 2.253, 180008: 3.2318, 183698: 4.816, 184046: 3.3756, 187114: 3.3058, 189082: 2.6313, 191073: 7.1439, 194186: 10.5448, 196839: 5.0881, 197443: 2.3005, 198589: 1.356, 198783: 6.0902, 199693: 1.8806, 202290: 5.4937, 206426: 3.2989, 209596: 8.3899, 211086: 6.8675, 211756: 3.6206, 214895: 7.6283, 214962: 3.0474, 215744: 6.154, 217856: 9.3128, 219087: 3.069, 219915: 0.6888, 221693: 3.9617, 221938: 20.5177, 223365: 5.5021, 223763: 3.0486, 227226: 9.7032, 228250: 1.4544, 228685: 2.3973, 230689: 3.5568, 230804: 10.6936, 231919: 4.2315, 234050: 6.5688, 235273: 1.0006, 235665: 7.4976, 237499: 6.1087, 240944: 0.707, 242794: 11.7705, 243890: 11.2248, 244714: 10.0115, 245044: 2.6616, 245415: 3.6283, 245951: 4.2876, 247372: 5.0636, 249180: 3.028, 249598: 5.0125, 250421: 6.2985, 250855: 1.7711, 251302: 12.5654, 251390: 7.6189, 253178: 7.0681, 257091: 3.9384, 258728: 2.4807, 261754: 10.4253}))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_reviews.select(\"text\", \"words\", \"term_frequency\", \"embedding\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind the representation of TF-IDF vectors - it's sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do It Yourself\n",
    "* calculate `word2vec` embeddings instead of TF-IDF\n",
    "* build a linear regression (predict stars by text)\n",
    "* split data into train and validation sets and evaluate your model\n",
    "* compare quality of models (TF-IDF vs word2vec, linear vs random forest vs gradient goosted trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
