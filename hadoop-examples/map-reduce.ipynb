{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop Streaming\n",
    "\n",
    "Usually MapReduce jobs are written in Java. Nevertheless, Hadoop has a feature called somewhat misleadingly [Hadoop Streaming](https://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html) which enables one to use Python or any other script language such as `shell` for developing mappers and reducers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Some Code\n",
    "\n",
    "First, we need to code our mapper. In case of Hadoop Streaming, a mapper is a script which gets some text from the standard input until the EOF and produces some text line by line to the standard output. For example, it can be like the following file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/python3\r\n",
      "\r\n",
      "counter = 0\r\n",
      "while True:\r\n",
      "    try:\r\n",
      "        counter += 1\r\n",
      "        input()\r\n",
      "    except EOFError:\r\n",
      "        break\r\n",
      "print(counter)\r\n"
     ]
    }
   ],
   "source": [
    "!cat mapper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind the first line (so-called [shebang](https://en.wikipedia.org/wiki/Shebang_(Unix))) - it's very important to keep it in place, since Hadoop doesn't know where your favourite Python executable is located. It could even be `#!/usr/bin/perl` or `#!/usr/bin/bash` as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script does nothing interesting, it simply goes through the file line by line until EOF and counts lines. Then it prints the total number of lines in a file.\n",
    "\n",
    "Of course, you can code anything more complicated: import additional packages, define functions, classes, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reducer looks similar since generally it does the same trick: goes through the lines of the standard input and prints something to the standard output. The main difference is that it has the output of the mapper as it's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/python3\r\n",
      "\r\n",
      "counter = 0\r\n",
      "while True:\r\n",
      "    try:\r\n",
      "        line = input()\r\n",
      "    except EOFError:\r\n",
      "        break\r\n",
      "    counter += int(line)\r\n",
      "print(counter)\r\n"
     ]
    }
   ],
   "source": [
    "!cat reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reducer sums integer values (which are the line counts produced by the mapper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing your code to the cluster\n",
    "\n",
    "Hadoop lives on a cluster, and your MapReduce jobs will run on the cluster too. Hadoop __can't__ execute any code from a local machine directly. That means we need to put out code to HDFS somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -put mapper.py code\n",
    "!hdfs dfs -put reducer.py code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to do that whenever your want to update your MapReduce jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running MapReduce\n",
    "\n",
    "We will use the `mapred streaming` command for running our Hadoop Streaming job. The description of parameters follows:\n",
    "* files - here we put a comma-separated list of our source code files __on HDFS__. In case of Python they are simple Python scripts but in case of Java they would be `jar` files\n",
    "* input - a file on HDFS to input to the mapper\n",
    "* output - some location to HDFS where to put the results (the output of the reducer)\n",
    "* mapper - the name of the mapper script\n",
    "* reducer - the name of the reducer script\n",
    "\n",
    "Let magic happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:19,322 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2020-10-23 19:20:19,400 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2020-10-23 19:20:19,401 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2020-10-23 19:20:19,411 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2020-10-23 19:20:19,839 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2020-10-23 19:20:19,860 INFO mapreduce.JobSubmitter: number of splits:8\n",
      "2020-10-23 19:20:20,064 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1720303681_0001\n",
      "2020-10-23 19:20:20,064 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2020-10-23 19:20:20,385 INFO mapred.LocalDistributedCacheManager: Localized file:/workdir/boris/projects/big-data-exercises/hadoop-examples/code/mapper.py as file:/tmp/hadoop-boris/mapred/local/job_local1720303681_0001_b33a27fb-19ea-4c3b-bb88-1b7917cced61/mapper.py\n",
      "2020-10-23 19:20:20,400 INFO mapred.LocalDistributedCacheManager: Localized file:/workdir/boris/projects/big-data-exercises/hadoop-examples/code/reducer.py as file:/tmp/hadoop-boris/mapred/local/job_local1720303681_0001_85f6ea3a-9bd2-4618-a3e5-fb474c0d2f48/reducer.py\n",
      "2020-10-23 19:20:20,463 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2020-10-23 19:20:20,465 INFO mapreduce.Job: Running job: job_local1720303681_0001\n",
      "2020-10-23 19:20:20,466 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2020-10-23 19:20:20,471 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "2020-10-23 19:20:20,475 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:20,475 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:20,534 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2020-10-23 19:20:20,540 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_m_000000_0\n",
      "2020-10-23 19:20:20,573 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:20,573 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:20,600 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:20,610 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:0+33554432\n",
      "2020-10-23 19:20:20,626 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:20,733 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:20,733 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:20,733 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:20,733 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:20,733 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:20,737 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:20,756 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:20,761 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "2020-10-23 19:20:20,761 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "2020-10-23 19:20:20,762 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "2020-10-23 19:20:20,762 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-10-23 19:20:20,763 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "2020-10-23 19:20:20,763 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "2020-10-23 19:20:20,763 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "2020-10-23 19:20:20,763 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-10-23 19:20:20,763 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "2020-10-23 19:20:20,764 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "2020-10-23 19:20:20,764 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2020-10-23 19:20:20,764 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "2020-10-23 19:20:20,781 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:20,781 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:20,783 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:20,903 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:20,950 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:21,075 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:21,267 INFO streaming.PipeMapRed: Records R/W=169985/1\n",
      "2020-10-23 19:20:21,285 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:21,308 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:21,323 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:21,324 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:21,324 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:21,324 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:21,324 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:21,351 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:21,378 INFO mapred.Task: Task:attempt_local1720303681_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:21,383 INFO mapred.LocalJobRunner: Records R/W=169985/1\n",
      "2020-10-23 19:20:21,383 INFO mapred.Task: Task 'attempt_local1720303681_0001_m_000000_0' done.\n",
      "2020-10-23 19:20:21,393 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33968119\n",
      "\t\tFILE: Number of bytes written=761829\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=169985\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=72\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33824768\n",
      "2020-10-23 19:20:21,394 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_m_000000_0\n",
      "2020-10-23 19:20:21,394 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_m_000001_0\n",
      "2020-10-23 19:20:21,400 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:21,401 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:21,401 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:21,404 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:33554432+33554432\n",
      "2020-10-23 19:20:21,411 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:21,440 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:21,441 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:21,441 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:21,441 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:21,441 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:21,442 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:21,496 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:21,496 INFO mapreduce.Job: Job job_local1720303681_0001 running in uber mode : false\n",
      "2020-10-23 19:20:21,526 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2020-10-23 19:20:21,548 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:21,549 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:21,550 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:21,588 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:21,606 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:21,746 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:21,858 INFO streaming.PipeMapRed: Records R/W=169364/1\n",
      "2020-10-23 19:20:21,859 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:21,861 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:21,864 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:21,864 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:21,864 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:21,865 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:21,865 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:21,877 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:21,883 INFO mapred.Task: Task:attempt_local1720303681_0001_m_000001_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:21,886 INFO mapred.LocalJobRunner: Records R/W=169364/1\n",
      "2020-10-23 19:20:21,886 INFO mapred.Task: Task 'attempt_local1720303681_0001_m_000001_0' done.\n",
      "2020-10-23 19:20:21,887 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67798218\n",
      "\t\tFILE: Number of bytes written=761877\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=169364\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:21,888 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_m_000001_0\n",
      "2020-10-23 19:20:21,888 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_m_000002_0\n",
      "2020-10-23 19:20:21,893 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:21,893 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:21,894 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:21,895 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:67108864+33554432\n",
      "2020-10-23 19:20:21,901 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:22,009 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:22,009 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:22,009 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:22,009 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:22,010 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:22,011 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:22,021 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:22,035 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,035 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,035 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,071 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,088 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,219 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,317 INFO streaming.PipeMapRed: Records R/W=167536/1\n",
      "2020-10-23 19:20:22,320 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:22,321 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:22,322 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:22,322 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:22,322 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:22,322 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:22,322 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:22,326 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:22,328 INFO mapred.Task: Task:attempt_local1720303681_0001_m_000002_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:22,329 INFO mapred.LocalJobRunner: Records R/W=167536/1\n",
      "2020-10-23 19:20:22,329 INFO mapred.Task: Task 'attempt_local1720303681_0001_m_000002_0' done.\n",
      "2020-10-23 19:20:22,331 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=101628317\n",
      "\t\tFILE: Number of bytes written=761925\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=167536\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:22,331 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_m_000002_0\n",
      "2020-10-23 19:20:22,331 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_m_000003_0\n",
      "2020-10-23 19:20:22,333 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:22,333 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:22,334 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:22,335 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:100663296+33554432\n",
      "2020-10-23 19:20:22,337 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:22,450 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:22,450 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:22,450 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:22,450 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:22,450 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:22,451 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:22,464 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:22,478 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,478 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,478 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,499 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,518 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,650 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:22,746 INFO streaming.PipeMapRed: Records R/W=165904/1\n",
      "2020-10-23 19:20:22,748 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:22,749 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:22,750 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:22,750 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:22,750 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:22,750 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:22,750 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:22,753 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:22,754 INFO mapred.Task: Task:attempt_local1720303681_0001_m_000003_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:22,756 INFO mapred.LocalJobRunner: Records R/W=165904/1\n",
      "2020-10-23 19:20:22,756 INFO mapred.Task: Task 'attempt_local1720303681_0001_m_000003_0' done.\n",
      "2020-10-23 19:20:22,757 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=135458416\n",
      "\t\tFILE: Number of bytes written=761973\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=165904\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:22,757 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_m_000003_0\n",
      "2020-10-23 19:20:22,757 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_m_000004_0\n",
      "2020-10-23 19:20:22,759 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:22,759 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:22,759 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:22,760 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:134217728+33554432\n",
      "2020-10-23 19:20:22,763 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:22,868 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:22,869 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:22,869 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:22,869 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:22,869 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:22,870 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:22,885 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:22,899 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,899 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,899 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,918 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:22,933 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,073 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,177 INFO streaming.PipeMapRed: Records R/W=166855/1\n",
      "2020-10-23 19:20:23,179 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:23,180 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:23,181 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:23,181 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:23,181 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:23,181 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:23,181 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:23,183 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:23,186 INFO mapred.Task: Task:attempt_local1720303681_0001_m_000004_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:23,187 INFO mapred.LocalJobRunner: Records R/W=166855/1\n",
      "2020-10-23 19:20:23,187 INFO mapred.Task: Task 'attempt_local1720303681_0001_m_000004_0' done.\n",
      "2020-10-23 19:20:23,187 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=169288003\n",
      "\t\tFILE: Number of bytes written=762021\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=166855\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:23,187 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_m_000004_0\n",
      "2020-10-23 19:20:23,187 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_m_000005_0\n",
      "2020-10-23 19:20:23,190 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:23,190 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:23,190 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:23,192 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:167772160+33554432\n",
      "2020-10-23 19:20:23,195 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:23,283 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:23,283 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:23,283 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:23,283 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:23,283 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:23,285 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:23,294 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:23,308 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,308 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,308 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,330 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,345 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,487 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,614 INFO streaming.PipeMapRed: Records R/W=167409/1\n",
      "2020-10-23 19:20:23,640 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:23,660 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:23,665 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:23,665 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:23,666 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:23,666 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:23,666 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:23,681 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:23,687 INFO mapred.Task: Task:attempt_local1720303681_0001_m_000005_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:23,690 INFO mapred.LocalJobRunner: Records R/W=167409/1\n",
      "2020-10-23 19:20:23,690 INFO mapred.Task: Task 'attempt_local1720303681_0001_m_000005_0' done.\n",
      "2020-10-23 19:20:23,691 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_m_000005_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=203117590\n",
      "\t\tFILE: Number of bytes written=762069\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=167409\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:23,692 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_m_000005_0\n",
      "2020-10-23 19:20:23,692 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_m_000006_0\n",
      "2020-10-23 19:20:23,699 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:23,699 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:23,700 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:23,703 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:201326592+33554432\n",
      "2020-10-23 19:20:23,709 INFO mapred.MapTask: numReduceTasks: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:23,744 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:23,744 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:23,744 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:23,744 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:23,744 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:23,746 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:23,780 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:23,796 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,796 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,796 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,823 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,841 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:23,964 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:24,056 INFO streaming.PipeMapRed: Records R/W=169533/1\n",
      "2020-10-23 19:20:24,059 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:24,060 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:24,060 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:24,060 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:24,060 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:24,060 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:24,060 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:24,062 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:24,064 INFO mapred.Task: Task:attempt_local1720303681_0001_m_000006_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:24,065 INFO mapred.LocalJobRunner: Records R/W=169533/1\n",
      "2020-10-23 19:20:24,066 INFO mapred.Task: Task 'attempt_local1720303681_0001_m_000006_0' done.\n",
      "2020-10-23 19:20:24,066 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_m_000006_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=236947177\n",
      "\t\tFILE: Number of bytes written=762117\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=169533\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:24,066 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_m_000006_0\n",
      "2020-10-23 19:20:24,066 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_m_000007_0\n",
      "2020-10-23 19:20:24,069 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:24,069 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:24,069 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:24,070 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:234881024+28608298\n",
      "2020-10-23 19:20:24,078 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:24,107 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:24,107 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:24,107 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:24,107 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:24,107 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:24,108 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:24,117 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:24,124 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:24,124 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:24,124 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:24,140 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:24,153 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:24,276 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:24,340 INFO streaming.PipeMapRed: Records R/W=144175/1\n",
      "2020-10-23 19:20:24,342 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:24,343 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:24,343 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:24,343 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:24,343 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:24,343 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:24,343 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:24,345 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:24,346 INFO mapred.Task: Task:attempt_local1720303681_0001_m_000007_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:24,348 INFO mapred.LocalJobRunner: Records R/W=144175/1\n",
      "2020-10-23 19:20:24,348 INFO mapred.Task: Task 'attempt_local1720303681_0001_m_000007_0' done.\n",
      "2020-10-23 19:20:24,348 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_m_000007_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=265783290\n",
      "\t\tFILE: Number of bytes written=762165\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=144175\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=28835902\n",
      "2020-10-23 19:20:24,348 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_m_000007_0\n",
      "2020-10-23 19:20:24,350 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2020-10-23 19:20:24,362 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2020-10-23 19:20:24,363 INFO mapred.LocalJobRunner: Starting task: attempt_local1720303681_0001_r_000000_0\n",
      "2020-10-23 19:20:24,379 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:24,379 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:24,379 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:24,383 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c4fe4d1\n",
      "2020-10-23 19:20:24,385 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2020-10-23 19:20:24,415 INFO reduce.MergeManagerImpl: The max number of bytes for a single in-memory shuffle cannot be larger than Integer.MAX_VALUE. Setting it to Integer.MAX_VALUE\n",
      "2020-10-23 19:20:24,415 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=22525089792, maxSingleShuffleLimit=2147483647, mergeThreshold=14866560000, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-10-23 19:20:24,418 INFO reduce.EventFetcher: attempt_local1720303681_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-10-23 19:20:24,472 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1720303681_0001_m_000005_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:24,477 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local1720303681_0001_m_000005_0\n",
      "2020-10-23 19:20:24,478 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12\n",
      "2020-10-23 19:20:24,482 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1720303681_0001_m_000002_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:24,484 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local1720303681_0001_m_000002_0\n",
      "2020-10-23 19:20:24,484 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 2, commitMemory -> 12, usedMemory ->24\n",
      "2020-10-23 19:20:24,485 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1720303681_0001_m_000003_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:24,486 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local1720303681_0001_m_000003_0\n",
      "2020-10-23 19:20:24,486 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 3, commitMemory -> 24, usedMemory ->36\n",
      "2020-10-23 19:20:24,488 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1720303681_0001_m_000006_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:24,489 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local1720303681_0001_m_000006_0\n",
      "2020-10-23 19:20:24,489 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 4, commitMemory -> 36, usedMemory ->48\n",
      "2020-10-23 19:20:24,490 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1720303681_0001_m_000000_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:24,490 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local1720303681_0001_m_000000_0\n",
      "2020-10-23 19:20:24,490 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 5, commitMemory -> 48, usedMemory ->60\n",
      "2020-10-23 19:20:24,492 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1720303681_0001_m_000007_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:24,493 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local1720303681_0001_m_000007_0\n",
      "2020-10-23 19:20:24,493 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 6, commitMemory -> 60, usedMemory ->72\n",
      "2020-10-23 19:20:24,494 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1720303681_0001_m_000001_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:24,494 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local1720303681_0001_m_000001_0\n",
      "2020-10-23 19:20:24,495 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 7, commitMemory -> 72, usedMemory ->84\n",
      "2020-10-23 19:20:24,496 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1720303681_0001_m_000004_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:24,496 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local1720303681_0001_m_000004_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:24,496 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 8, commitMemory -> 84, usedMemory ->96\n",
      "2020-10-23 19:20:24,497 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2020-10-23 19:20:24,498 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
      "2020-10-23 19:20:24,498 INFO reduce.MergeManagerImpl: finalMerge called with 8 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-10-23 19:20:24,505 INFO mapred.Merger: Merging 8 sorted segments\n",
      "2020-10-23 19:20:24,505 INFO mapred.Merger: Down to the last merge-pass, with 8 segments left of total size: 24 bytes\n",
      "2020-10-23 19:20:24,506 INFO reduce.MergeManagerImpl: Merged 8 segments, 96 bytes to disk to satisfy reduce memory limit\n",
      "2020-10-23 19:20:24,507 INFO reduce.MergeManagerImpl: Merging 1 files, 86 bytes from disk\n",
      "2020-10-23 19:20:24,507 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-10-23 19:20:24,507 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2020-10-23 19:20:24,508 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 73 bytes\n",
      "2020-10-23 19:20:24,508 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
      "2020-10-23 19:20:24,519 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./reducer.py]\n",
      "2020-10-23 19:20:24,521 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-10-23 19:20:24,522 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-10-23 19:20:24,535 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:24,549 INFO streaming.PipeMapRed: Records R/W=8/1\n",
      "2020-10-23 19:20:24,551 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:24,552 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:24,553 INFO mapred.Task: Task:attempt_local1720303681_0001_r_000000_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:24,553 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
      "2020-10-23 19:20:24,553 INFO mapred.Task: Task attempt_local1720303681_0001_r_000000_0 is allowed to commit now\n",
      "2020-10-23 19:20:24,556 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1720303681_0001_r_000000_0' to file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/result\n",
      "2020-10-23 19:20:24,557 INFO mapred.LocalJobRunner: Records R/W=8/1 > reduce\n",
      "2020-10-23 19:20:24,557 INFO mapred.Task: Task 'attempt_local1720303681_0001_r_000000_0' done.\n",
      "2020-10-23 19:20:24,557 INFO mapred.Task: Final Counters for attempt_local1720303681_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=265783760\n",
      "\t\tFILE: Number of bytes written=762272\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=8\n",
      "\t\tReduce shuffle bytes=128\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=8\n",
      "\t\tShuffled Maps =8\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tGC time elapsed (ms)=20\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=21\n",
      "2020-10-23 19:20:24,557 INFO mapred.LocalJobRunner: Finishing task: attempt_local1720303681_0001_r_000000_0\n",
      "2020-10-23 19:20:24,557 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2020-10-23 19:20:24,586 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2020-10-23 19:20:24,604 INFO mapreduce.Job: Job job_local1720303681_0001 completed successfully\n",
      "2020-10-23 19:20:24,625 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1479772890\n",
      "\t\tFILE: Number of bytes written=6858248\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1320761\n",
      "\t\tMap output records=8\n",
      "\t\tMap output bytes=64\n",
      "\t\tMap output materialized bytes=128\n",
      "\t\tInput split bytes=1208\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=8\n",
      "\t\tReduce shuffle bytes=128\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =8\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tGC time elapsed (ms)=92\n",
      "\t\tTotal committed heap usage (bytes)=19327352832\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=265633854\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=21\n",
      "2020-10-23 19:20:24,626 INFO streaming.StreamJob: Output directory: data/result\n"
     ]
    }
   ],
   "source": [
    "!mapred streaming \\\n",
    "    -files code/mapper.py,code/reducer.py \\\n",
    "    -input data/yelp_academic_dataset_tip.json \\\n",
    "    -output data/result \\\n",
    "    -mapper mapper.py \\\n",
    "    -reducer reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 boris atg          0 2020-10-23 19:20 data/result/_SUCCESS\n",
      "-rw-r--r--   1 boris atg          9 2020-10-23 19:20 data/result/part-00000\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls data/result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind the file \\_SUCCESS. It appears only when a MapReduce job finished successfully. Since the reducer outputs a file, here it is - `part-00000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320769\t\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat data/result/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of lines in our input file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Parts\n",
    "\n",
    "Let's run the same MapReduce job but without a reducer (then it's considered to act as identity and print exactly what it reads from it's input):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:32,026 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2020-10-23 19:20:32,106 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2020-10-23 19:20:32,106 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2020-10-23 19:20:32,117 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2020-10-23 19:20:32,355 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2020-10-23 19:20:32,368 INFO mapreduce.JobSubmitter: number of splits:8\n",
      "2020-10-23 19:20:32,500 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local175791011_0001\n",
      "2020-10-23 19:20:32,500 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2020-10-23 19:20:32,728 INFO mapred.LocalDistributedCacheManager: Localized file:/workdir/boris/projects/big-data-exercises/hadoop-examples/code/mapper.py as file:/tmp/hadoop-boris/mapred/local/job_local175791011_0001_cbd5e7ce-bf55-4b0e-aa56-e97dd6c0600a/mapper.py\n",
      "2020-10-23 19:20:32,755 INFO mapred.LocalDistributedCacheManager: Localized file:/workdir/boris/projects/big-data-exercises/hadoop-examples/code/reducer.py as file:/tmp/hadoop-boris/mapred/local/job_local175791011_0001_f4c609a7-8e19-4144-a43b-89f1b86bbca1/reducer.py\n",
      "2020-10-23 19:20:32,796 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2020-10-23 19:20:32,799 INFO mapreduce.Job: Running job: job_local175791011_0001\n",
      "2020-10-23 19:20:32,800 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2020-10-23 19:20:32,804 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "2020-10-23 19:20:32,808 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:32,808 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:32,844 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2020-10-23 19:20:32,847 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_m_000000_0\n",
      "2020-10-23 19:20:32,870 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:32,870 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:32,892 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:32,899 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:0+33554432\n",
      "2020-10-23 19:20:32,910 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:32,944 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:32,944 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:32,944 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:32,944 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:32,945 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:32,948 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:32,958 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:32,962 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "2020-10-23 19:20:32,963 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "2020-10-23 19:20:32,963 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "2020-10-23 19:20:32,963 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-10-23 19:20:32,964 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "2020-10-23 19:20:32,964 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "2020-10-23 19:20:32,964 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "2020-10-23 19:20:32,964 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-10-23 19:20:32,964 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "2020-10-23 19:20:32,965 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "2020-10-23 19:20:32,965 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2020-10-23 19:20:32,965 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "2020-10-23 19:20:32,976 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:32,976 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:32,977 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:32,990 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,015 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,163 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,258 INFO streaming.PipeMapRed: Records R/W=169985/1\n",
      "2020-10-23 19:20:33,260 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:33,261 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:33,264 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:33,264 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:33,264 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:33,264 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:33,264 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:33,270 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:33,278 INFO mapred.Task: Task:attempt_local175791011_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:33,279 INFO mapred.LocalJobRunner: Records R/W=169985/1\n",
      "2020-10-23 19:20:33,279 INFO mapred.Task: Task 'attempt_local175791011_0001_m_000000_0' done.\n",
      "2020-10-23 19:20:33,286 INFO mapred.Task: Final Counters for attempt_local175791011_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33968119\n",
      "\t\tFILE: Number of bytes written=757181\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=169985\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=27\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33824768\n",
      "2020-10-23 19:20:33,286 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_m_000000_0\n",
      "2020-10-23 19:20:33,286 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_m_000001_0\n",
      "2020-10-23 19:20:33,287 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:33,288 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:33,288 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:33,289 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:33554432+33554432\n",
      "2020-10-23 19:20:33,291 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:33,319 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:33,319 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:33,319 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:33,319 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:33,319 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:33,320 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:33,326 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:33,336 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,336 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,336 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,356 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,369 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,489 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,616 INFO streaming.PipeMapRed: Records R/W=169364/1\n",
      "2020-10-23 19:20:33,620 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:33,620 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:33,621 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:33,621 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:33,621 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:33,621 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:33,621 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:33,623 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:33,625 INFO mapred.Task: Task:attempt_local175791011_0001_m_000001_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:33,626 INFO mapred.LocalJobRunner: Records R/W=169364/1\n",
      "2020-10-23 19:20:33,626 INFO mapred.Task: Task 'attempt_local175791011_0001_m_000001_0' done.\n",
      "2020-10-23 19:20:33,626 INFO mapred.Task: Final Counters for attempt_local175791011_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67798218\n",
      "\t\tFILE: Number of bytes written=757229\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=169364\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:33,627 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_m_000001_0\n",
      "2020-10-23 19:20:33,627 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_m_000002_0\n",
      "2020-10-23 19:20:33,628 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:33,628 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:33,628 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:33,629 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:67108864+33554432\n",
      "2020-10-23 19:20:33,631 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:33,659 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:33,659 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:33,659 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:33,659 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:33,659 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:33,660 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:33,666 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:33,675 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,676 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,676 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,695 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,712 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,806 INFO mapreduce.Job: Job job_local175791011_0001 running in uber mode : false\n",
      "2020-10-23 19:20:33,811 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2020-10-23 19:20:33,835 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,929 INFO streaming.PipeMapRed: Records R/W=167536/1\n",
      "2020-10-23 19:20:33,931 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:33,931 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:33,932 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:33,932 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:33,932 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:33,932 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:33,932 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:33,934 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:33,935 INFO mapred.Task: Task:attempt_local175791011_0001_m_000002_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:33,936 INFO mapred.LocalJobRunner: Records R/W=167536/1\n",
      "2020-10-23 19:20:33,936 INFO mapred.Task: Task 'attempt_local175791011_0001_m_000002_0' done.\n",
      "2020-10-23 19:20:33,937 INFO mapred.Task: Final Counters for attempt_local175791011_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=101628317\n",
      "\t\tFILE: Number of bytes written=757277\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=167536\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:33,937 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_m_000002_0\n",
      "2020-10-23 19:20:33,937 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_m_000003_0\n",
      "2020-10-23 19:20:33,938 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:33,938 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:33,939 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:33,939 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:100663296+33554432\n",
      "2020-10-23 19:20:33,941 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:33,969 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:33,970 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:33,970 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:33,970 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:33,970 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:33,971 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:33,976 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:33,984 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,984 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:33,984 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,004 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,017 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,136 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:34,222 INFO streaming.PipeMapRed: Records R/W=165904/1\n",
      "2020-10-23 19:20:34,225 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:34,225 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:34,226 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:34,226 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:34,226 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:34,226 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:34,226 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:34,227 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:34,229 INFO mapred.Task: Task:attempt_local175791011_0001_m_000003_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:34,230 INFO mapred.LocalJobRunner: Records R/W=165904/1\n",
      "2020-10-23 19:20:34,230 INFO mapred.Task: Task 'attempt_local175791011_0001_m_000003_0' done.\n",
      "2020-10-23 19:20:34,231 INFO mapred.Task: Final Counters for attempt_local175791011_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=135458416\n",
      "\t\tFILE: Number of bytes written=757325\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=165904\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:34,231 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_m_000003_0\n",
      "2020-10-23 19:20:34,231 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_m_000004_0\n",
      "2020-10-23 19:20:34,233 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:34,233 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:34,233 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:34,234 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:134217728+33554432\n",
      "2020-10-23 19:20:34,236 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:34,265 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:34,265 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:34,265 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:34,265 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:34,265 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:34,266 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:34,277 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:34,287 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,287 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,287 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,308 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,321 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,447 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,540 INFO streaming.PipeMapRed: Records R/W=166855/1\n",
      "2020-10-23 19:20:34,541 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:34,542 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:34,544 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:34,544 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:34,544 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:34,544 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:34,544 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:34,545 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:34,547 INFO mapred.Task: Task:attempt_local175791011_0001_m_000004_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:34,548 INFO mapred.LocalJobRunner: Records R/W=166855/1\n",
      "2020-10-23 19:20:34,548 INFO mapred.Task: Task 'attempt_local175791011_0001_m_000004_0' done.\n",
      "2020-10-23 19:20:34,549 INFO mapred.Task: Final Counters for attempt_local175791011_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=169288003\n",
      "\t\tFILE: Number of bytes written=757373\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=166855\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:34,549 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_m_000004_0\n",
      "2020-10-23 19:20:34,549 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_m_000005_0\n",
      "2020-10-23 19:20:34,550 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:34,550 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:34,550 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:34,552 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:167772160+33554432\n",
      "2020-10-23 19:20:34,554 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:34,585 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:34,585 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:34,585 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:34,585 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:34,585 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:34,586 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:34,594 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:34,601 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,601 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,601 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,621 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,635 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,755 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,844 INFO streaming.PipeMapRed: Records R/W=167409/1\n",
      "2020-10-23 19:20:34,846 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:34,846 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:34,847 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:34,847 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:34,847 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:34,847 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:34,847 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:34,849 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:34,851 INFO mapred.Task: Task:attempt_local175791011_0001_m_000005_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:34,853 INFO mapred.LocalJobRunner: Records R/W=167409/1\n",
      "2020-10-23 19:20:34,853 INFO mapred.Task: Task 'attempt_local175791011_0001_m_000005_0' done.\n",
      "2020-10-23 19:20:34,853 INFO mapred.Task: Final Counters for attempt_local175791011_0001_m_000005_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=203117590\n",
      "\t\tFILE: Number of bytes written=757421\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=167409\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:34,853 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_m_000005_0\n",
      "2020-10-23 19:20:34,853 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_m_000006_0\n",
      "2020-10-23 19:20:34,855 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:34,855 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:34,855 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:34,856 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:201326592+33554432\n",
      "2020-10-23 19:20:34,858 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:34,886 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:34,886 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:34,886 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:34,886 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:34,886 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:34,887 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:34,895 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:34,903 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,904 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,904 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,924 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:34,938 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:35,060 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:35,155 INFO streaming.PipeMapRed: Records R/W=169533/1\n",
      "2020-10-23 19:20:35,157 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:35,158 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:35,158 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:35,158 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:35,158 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:35,158 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:35,158 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:35,160 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:35,162 INFO mapred.Task: Task:attempt_local175791011_0001_m_000006_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:35,163 INFO mapred.LocalJobRunner: Records R/W=169533/1\n",
      "2020-10-23 19:20:35,163 INFO mapred.Task: Task 'attempt_local175791011_0001_m_000006_0' done.\n",
      "2020-10-23 19:20:35,163 INFO mapred.Task: Final Counters for attempt_local175791011_0001_m_000006_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=236947177\n",
      "\t\tFILE: Number of bytes written=757469\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=169533\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "2020-10-23 19:20:35,164 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_m_000006_0\n",
      "2020-10-23 19:20:35,164 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_m_000007_0\n",
      "2020-10-23 19:20:35,165 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:35,165 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:35,165 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:35,166 INFO mapred.MapTask: Processing split: file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/yelp_academic_dataset_tip.json:234881024+28608298\n",
      "2020-10-23 19:20:35,169 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2020-10-23 19:20:35,197 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-10-23 19:20:35,197 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2020-10-23 19:20:35,197 INFO mapred.MapTask: soft limit at 83886080\n",
      "2020-10-23 19:20:35,197 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2020-10-23 19:20:35,197 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2020-10-23 19:20:35,198 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-10-23 19:20:35,204 INFO streaming.PipeMapRed: PipeMapRed exec [/workdir/boris/projects/big-data-exercises/hadoop-examples/./mapper.py]\n",
      "2020-10-23 19:20:35,211 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:35,211 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:35,211 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:35,232 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:35,244 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:35,366 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2020-10-23 19:20:35,428 INFO streaming.PipeMapRed: Records R/W=144175/1\n",
      "2020-10-23 19:20:35,431 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2020-10-23 19:20:35,431 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2020-10-23 19:20:35,432 INFO mapred.LocalJobRunner: \n",
      "2020-10-23 19:20:35,432 INFO mapred.MapTask: Starting flush of map output\n",
      "2020-10-23 19:20:35,432 INFO mapred.MapTask: Spilling map output\n",
      "2020-10-23 19:20:35,432 INFO mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600\n",
      "2020-10-23 19:20:35,432 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2020-10-23 19:20:35,435 INFO mapred.MapTask: Finished spill 0\n",
      "2020-10-23 19:20:35,436 INFO mapred.Task: Task:attempt_local175791011_0001_m_000007_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:35,438 INFO mapred.LocalJobRunner: Records R/W=144175/1\n",
      "2020-10-23 19:20:35,438 INFO mapred.Task: Task 'attempt_local175791011_0001_m_000007_0' done.\n",
      "2020-10-23 19:20:35,438 INFO mapred.Task: Final Counters for attempt_local175791011_0001_m_000007_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=265783290\n",
      "\t\tFILE: Number of bytes written=757517\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=144175\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=8\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tInput split bytes=151\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=28835902\n",
      "2020-10-23 19:20:35,438 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_m_000007_0\n",
      "2020-10-23 19:20:35,439 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2020-10-23 19:20:35,442 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2020-10-23 19:20:35,442 INFO mapred.LocalJobRunner: Starting task: attempt_local175791011_0001_r_000000_0\n",
      "2020-10-23 19:20:35,451 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2020-10-23 19:20:35,451 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-10-23 19:20:35,451 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-10-23 19:20:35,465 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ed4fcf6\n",
      "2020-10-23 19:20:35,466 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2020-10-23 19:20:35,481 INFO reduce.MergeManagerImpl: The max number of bytes for a single in-memory shuffle cannot be larger than Integer.MAX_VALUE. Setting it to Integer.MAX_VALUE\n",
      "2020-10-23 19:20:35,481 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=22525089792, maxSingleShuffleLimit=2147483647, mergeThreshold=14866560000, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-10-23 19:20:35,483 INFO reduce.EventFetcher: attempt_local175791011_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-10-23 19:20:35,503 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local175791011_0001_m_000000_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:35,506 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local175791011_0001_m_000000_0\n",
      "2020-10-23 19:20:35,507 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12\n",
      "2020-10-23 19:20:35,509 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local175791011_0001_m_000003_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:35,510 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local175791011_0001_m_000003_0\n",
      "2020-10-23 19:20:35,510 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 2, commitMemory -> 12, usedMemory ->24\n",
      "2020-10-23 19:20:35,510 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local175791011_0001_m_000006_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:35,511 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local175791011_0001_m_000006_0\n",
      "2020-10-23 19:20:35,511 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 3, commitMemory -> 24, usedMemory ->36\n",
      "2020-10-23 19:20:35,512 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local175791011_0001_m_000002_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:35,513 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local175791011_0001_m_000002_0\n",
      "2020-10-23 19:20:35,513 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 4, commitMemory -> 36, usedMemory ->48\n",
      "2020-10-23 19:20:35,514 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local175791011_0001_m_000005_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:35,514 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local175791011_0001_m_000005_0\n",
      "2020-10-23 19:20:35,514 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 5, commitMemory -> 48, usedMemory ->60\n",
      "2020-10-23 19:20:35,515 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local175791011_0001_m_000004_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:35,515 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local175791011_0001_m_000004_0\n",
      "2020-10-23 19:20:35,515 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 6, commitMemory -> 60, usedMemory ->72\n",
      "2020-10-23 19:20:35,516 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local175791011_0001_m_000007_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:35,516 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local175791011_0001_m_000007_0\n",
      "2020-10-23 19:20:35,517 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 7, commitMemory -> 72, usedMemory ->84\n",
      "2020-10-23 19:20:35,517 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local175791011_0001_m_000001_0 decomp: 12 len: 16 to MEMORY\n",
      "2020-10-23 19:20:35,518 INFO reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local175791011_0001_m_000001_0\n",
      "2020-10-23 19:20:35,518 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 8, commitMemory -> 84, usedMemory ->96\n",
      "2020-10-23 19:20:35,518 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2020-10-23 19:20:35,519 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
      "2020-10-23 19:20:35,519 INFO reduce.MergeManagerImpl: finalMerge called with 8 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-10-23 19:20:35,523 INFO mapred.Merger: Merging 8 sorted segments\n",
      "2020-10-23 19:20:35,523 INFO mapred.Merger: Down to the last merge-pass, with 8 segments left of total size: 24 bytes\n",
      "2020-10-23 19:20:35,524 INFO reduce.MergeManagerImpl: Merged 8 segments, 96 bytes to disk to satisfy reduce memory limit\n",
      "2020-10-23 19:20:35,525 INFO reduce.MergeManagerImpl: Merging 1 files, 86 bytes from disk\n",
      "2020-10-23 19:20:35,525 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-10-23 19:20:35,525 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2020-10-23 19:20:35,525 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 73 bytes\n",
      "2020-10-23 19:20:35,525 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
      "2020-10-23 19:20:35,529 INFO mapred.Task: Task:attempt_local175791011_0001_r_000000_0 is done. And is in the process of committing\n",
      "2020-10-23 19:20:35,530 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
      "2020-10-23 19:20:35,530 INFO mapred.Task: Task attempt_local175791011_0001_r_000000_0 is allowed to commit now\n",
      "2020-10-23 19:20:35,531 INFO output.FileOutputCommitter: Saved output of task 'attempt_local175791011_0001_r_000000_0' to file:/workdir/boris/projects/big-data-exercises/hadoop-examples/data/multi_result\n",
      "2020-10-23 19:20:35,532 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "2020-10-23 19:20:35,532 INFO mapred.Task: Task 'attempt_local175791011_0001_r_000000_0' done.\n",
      "2020-10-23 19:20:35,532 INFO mapred.Task: Final Counters for attempt_local175791011_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=265783760\n",
      "\t\tFILE: Number of bytes written=757679\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=8\n",
      "\t\tReduce shuffle bytes=128\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=8\n",
      "\t\tSpilled Records=8\n",
      "\t\tShuffled Maps =8\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tGC time elapsed (ms)=10\n",
      "\t\tTotal committed heap usage (bytes)=2147483648\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=76\n",
      "2020-10-23 19:20:35,532 INFO mapred.LocalJobRunner: Finishing task: attempt_local175791011_0001_r_000000_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 19:20:35,532 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2020-10-23 19:20:35,834 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2020-10-23 19:20:35,834 INFO mapreduce.Job: Job job_local175791011_0001 completed successfully\n",
      "2020-10-23 19:20:35,849 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1479772890\n",
      "\t\tFILE: Number of bytes written=6816471\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1320761\n",
      "\t\tMap output records=8\n",
      "\t\tMap output bytes=64\n",
      "\t\tMap output materialized bytes=128\n",
      "\t\tInput split bytes=1208\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=8\n",
      "\t\tReduce shuffle bytes=128\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=8\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =8\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tGC time elapsed (ms)=37\n",
      "\t\tTotal committed heap usage (bytes)=19327352832\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=265633854\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=76\n",
      "2020-10-23 19:20:35,849 INFO streaming.StreamJob: Output directory: data/multi_result\n"
     ]
    }
   ],
   "source": [
    "!mapred streaming \\\n",
    "    -files code/mapper.py,code/reducer.py \\\n",
    "    -input data/yelp_academic_dataset_tip.json \\\n",
    "    -output data/multi_result \\\n",
    "    -mapper mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 boris atg          0 2020-10-23 19:20 data/multi_result/_SUCCESS\r\n",
      "-rw-r--r--   1 boris atg         64 2020-10-23 19:20 data/multi_result/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls data/multi_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there is only one resulting file, it has several lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144176\t\r\n",
      "165905\t\r\n",
      "166856\t\r\n",
      "167410\t\r\n",
      "167537\t\r\n",
      "169365\t\r\n",
      "169534\t\r\n",
      "169986\t\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat data/multi_result/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That happened because our mapper was run in parallel. You can wonder why it was slow then. The answer is quite simple - Python is an interpreted language, so it would be faster if we were using C++ or Java for our mappers and reducers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do It Yourself\n",
    "* code a mapper for counting words or characters, not lines\n",
    "* code a reducer to count lines, words, and symbols in one job\n",
    "* code a mapper to sum over the `compliment_count` field value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
